{
    "docs": [
        {
            "location": "/", 
            "text": "What is Autostrap?\n\n\nEnvironment\n\n\nHistory\n\n\nHow to Read this Document\n\n\nContact and Contributions\n\n\n\n\n\n\nWhat is Autostrap?\n\n\nAutostrap\n is a framework for deploying, configuring and orchestrating a set of\nvirtual or physical machines that act in concert to provide a service, such as\na web shop. It consists of known-good sample configuration for a range of\nservices, sample \nHeat\n templates for\nservice clouds (or stacks, as Heat terms them) of one or more machines\nproviding these services, and a set of bootstrapping scripts for setting the\nmachines up for \nPuppet\n configuration. It is designed to\nbe easily extended with user or project specific configuration and Puppet code.\nAll components are available under an \nApache 2.0 license\n.\n\n\nAutostrap has been developed and tested on Ubuntu 14.04. It may work for other\nDebian flavoured systems, but none have been tested so far.\n\n\nEnvironment\n\n\nCloudstrap can either run standalone on any Ubuntu 14.04 with an Internet\nconnection or it can be launched through Openstack's \nHeat\n\norchestration tool. Porting to Cloud environments other than Openstack should\nnot pose too great a challenge, but so far this has not been put to the test.\n\n\nHistory\n\n\nAutostrap started out as an internal Project at \nSyseleven\n, where\nit was used to configure various services running as \nHeat\n stacks\non Syseleven's Openstack cloud. While it eventually turned out not to be ideal\nfor Syseleven's intended use in managed hosting, it is nonetheless a very\nuseful tool for building infrastructure automatically and reproducibly. \nSyseleven kindly gave permission to release the code base to the community, the\nresults of which you are looking at now.\n\n\nHow to Read this Document\n\n\nIf you are entirely new to Autostrap, we recommend starting with the\n\nComponents\n and \nEntry Points\n sections. The former will\ngive you an overview of what components Autostrap consists of, the latter will\ngive you an idea of how and where you can kick off the bootstrapping process.\nOnce you are through with these two sections it's probably best to take some\ntime to read \nLife of a Stack\n. It will give you a birds-eye\noverview of how Autostrap bootstraps a blank VM to a point where it can run\npuppet.\n\n\nAfter that, it's probably best to get your hands dirty and follow the\ninstructions in the \nDeployment Workflow\n section to deploy your\nfirst Autostrap based service stack.\n\n\nFinally, you will find detailed reference documentation in the following\nsections:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration Sources\n\n\nDiscusses all knobs and dials available for configuring Autostrap in detail. Be sure to read this section before building a Autostrap based production setup.\n\n\n\n\n\n\nGlossary\n\n\nA glossary of terms we use in this document.\n\n\n\n\n\n\nHow do I...\n\n\nShort howto guides for various common tasks.\n\n\n\n\n\n\n\n\nContact and Contributions\n\n\nFor now, use our IRC channel \n#autostrap\n on\n\nFreeNode\n to get in touch. We do not have a mailing\nlist, yet. For Bug reports/feature requests, please raise an issue on\nour \nGithub page\n.\n\n\nThere is no formal contribution process right now. Just submit a pull request\non Github. We recommend discussing large and/or breaking changes in the IRC\nchannel first.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#what-is-autostrap", 
            "text": "Autostrap  is a framework for deploying, configuring and orchestrating a set of\nvirtual or physical machines that act in concert to provide a service, such as\na web shop. It consists of known-good sample configuration for a range of\nservices, sample  Heat  templates for\nservice clouds (or stacks, as Heat terms them) of one or more machines\nproviding these services, and a set of bootstrapping scripts for setting the\nmachines up for  Puppet  configuration. It is designed to\nbe easily extended with user or project specific configuration and Puppet code.\nAll components are available under an  Apache 2.0 license .  Autostrap has been developed and tested on Ubuntu 14.04. It may work for other\nDebian flavoured systems, but none have been tested so far.", 
            "title": "What is Autostrap?"
        }, 
        {
            "location": "/#environment", 
            "text": "Cloudstrap can either run standalone on any Ubuntu 14.04 with an Internet\nconnection or it can be launched through Openstack's  Heat \norchestration tool. Porting to Cloud environments other than Openstack should\nnot pose too great a challenge, but so far this has not been put to the test.", 
            "title": "Environment"
        }, 
        {
            "location": "/#history", 
            "text": "Autostrap started out as an internal Project at  Syseleven , where\nit was used to configure various services running as  Heat  stacks\non Syseleven's Openstack cloud. While it eventually turned out not to be ideal\nfor Syseleven's intended use in managed hosting, it is nonetheless a very\nuseful tool for building infrastructure automatically and reproducibly. \nSyseleven kindly gave permission to release the code base to the community, the\nresults of which you are looking at now.", 
            "title": "History"
        }, 
        {
            "location": "/#how-to-read-this-document", 
            "text": "If you are entirely new to Autostrap, we recommend starting with the Components  and  Entry Points  sections. The former will\ngive you an overview of what components Autostrap consists of, the latter will\ngive you an idea of how and where you can kick off the bootstrapping process.\nOnce you are through with these two sections it's probably best to take some\ntime to read  Life of a Stack . It will give you a birds-eye\noverview of how Autostrap bootstraps a blank VM to a point where it can run\npuppet.  After that, it's probably best to get your hands dirty and follow the\ninstructions in the  Deployment Workflow  section to deploy your\nfirst Autostrap based service stack.  Finally, you will find detailed reference documentation in the following\nsections:           Configuration Sources  Discusses all knobs and dials available for configuring Autostrap in detail. Be sure to read this section before building a Autostrap based production setup.    Glossary  A glossary of terms we use in this document.    How do I...  Short howto guides for various common tasks.", 
            "title": "How to Read this Document"
        }, 
        {
            "location": "/#contact-and-contributions", 
            "text": "For now, use our IRC channel  #autostrap  on FreeNode  to get in touch. We do not have a mailing\nlist, yet. For Bug reports/feature requests, please raise an issue on\nour  Github page .  There is no formal contribution process right now. Just submit a pull request\non Github. We recommend discussing large and/or breaking changes in the IRC\nchannel first.", 
            "title": "Contact and Contributions"
        }, 
        {
            "location": "/components/", 
            "text": "Core Components\n\n\nPuppet Modules\n\n\n\n\n\n\nIn this section we will give a brief rundown of all the components that make up\nAutostrap. It lists all the git repositories the components of Autostrap\nreside in and gives a high-level description of these components. All\nrepositories are on Github, with links provided in this section.\n\n\nA note to users: for setting up your service cloud, you will usually only need\na fork of \nproject-config\n and a checkout of\n\nautostrap-utils\n. The latter is optional but recommended\nsince it provides convenient development tools.\n\n\nCore Components\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nbootstrap-scripts\n\n\ncontains the bootstrap scripts that generate a \nhiera.yaml\n and get the machine to a point where it can run Puppet.\n\n\n\n\n\n\n \nglobal-config\n\n\ncontains known-good sample configuration in the shape of [Configuration Topics]{../glossary/topic.md}. Before you implement something from scratch you should browse this repository for an existing solution you might be able to customize to meet your needs.\n\n\n\n\n\n\n \nproject-config\n\n\nis an example repository that demonstrates and documents the structure and semantics of a project specific configuration repository. To use Autostrap, fork this repository and use it as a base for your custom configuration.\n\n\n\n\n\n\n \nautostrap-utils\n\n\ncontains useful utilities for building clouds using Autostrap.\n\n\n\n\n\n\n\n\nPuppet Modules\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npuppet-autopuppet\n\n\nSets up a Puppet master, Puppet agent or masterless puppet, including Sensu monitoring if desired.\n\n\n\n\n\n\npuppet-base\n\n\nSets up a sane environment, installs useful packages tweaks sysctls and a range of other things.\n\n\n\n\n\n\npuppet-docbuild\n\n\nSets up build dependencies and automatically builds this documentation from its \nmkdocs\n source.\n\n\n\n\n\n\npuppet-openstackfacts\n\n\nContains various \nFacter\n facts used by Autostrap.\n\n\n\n\n\n\npuppet-repodeploy\n\n\nwraps \npuppetlabs-vcsrepo\n so it can be configured through a Hiera hash containing multiple repositories.\n\n\n\n\n\n\npuppet-ssh\n\n\nConfigures the \nSSH\n daemon and deploys SSH authorized keys.", 
            "title": "Components"
        }, 
        {
            "location": "/components/#core-components", 
            "text": "bootstrap-scripts  contains the bootstrap scripts that generate a  hiera.yaml  and get the machine to a point where it can run Puppet.      global-config  contains known-good sample configuration in the shape of [Configuration Topics]{../glossary/topic.md}. Before you implement something from scratch you should browse this repository for an existing solution you might be able to customize to meet your needs.      project-config  is an example repository that demonstrates and documents the structure and semantics of a project specific configuration repository. To use Autostrap, fork this repository and use it as a base for your custom configuration.      autostrap-utils  contains useful utilities for building clouds using Autostrap.", 
            "title": "Core Components"
        }, 
        {
            "location": "/components/#puppet-modules", 
            "text": "puppet-autopuppet  Sets up a Puppet master, Puppet agent or masterless puppet, including Sensu monitoring if desired.    puppet-base  Sets up a sane environment, installs useful packages tweaks sysctls and a range of other things.    puppet-docbuild  Sets up build dependencies and automatically builds this documentation from its  mkdocs  source.    puppet-openstackfacts  Contains various  Facter  facts used by Autostrap.    puppet-repodeploy  wraps  puppetlabs-vcsrepo  so it can be configured through a Hiera hash containing multiple repositories.    puppet-ssh  Configures the  SSH  daemon and deploys SSH authorized keys.", 
            "title": "Puppet Modules"
        }, 
        {
            "location": "/entry/", 
            "text": "Depending on the platform Autostrap is deployed on, there are various entry\npoints into the bootstrapping process. We refer to these entry points as \nBootstrapping\nStage 0\n. The first common point for all platforms is the\n\ninitialize_instance\n script.\nThis script we also refer to as \nBootstrapping Stage 1\n. It is the starting\npoint for the actual bootstrapping process.  Currently, there are the following\nStage 0 mechanisms for calling it:\n\n\nHeat Resource\n\n\nFor Openstack platforms we developed the \nAS::autostrap\n Heat\nresource. It generates a user-data script ready to be passed into\n\nOS::Nova::Server\n instances. This script turns the parameters\nit receives through Heat into environment variables, clones\n\nbootstrap-scripts\n and launches\n\ninitialize_instance\n in this environment. Usually\nyou will only need one instance of this resource per Heat stack, i.e. you can\npass the same generated script to all Nova servers in your stack.\n\n\nautostrap.standalone\n\n\nFor environments without Heat and cloud-init we developed\n\nautostrap.standalone\n.\nThis script provides the same environment as the\n\nAS::autostrap\n Heat\nresource and invokes initialize_instance as well. It emulates the Heat based\nparametrization mechanisms detailed in the \nLife of a Stack\n section with the\nfollowing two mechanisms:\n\n\n\n\n\n\nParameters that are passed into \nAS::autostrap\n as Heat properties are retrieved from identically named environment variables.\n\n\n\n\n\n\ncloud-init metadata parameters are passed as \n=\n delimited key-value arguments to \nautostrap.standalone\n's \n-m\n option.\n\n\n\n\n\n\nExample: \n\n\nautostrap.standalone -m topics=puppet-agent \\\n                      -m nodetype=appserver", 
            "title": "Entry Points"
        }, 
        {
            "location": "/entry/#heat-resource", 
            "text": "For Openstack platforms we developed the  AS::autostrap  Heat\nresource. It generates a user-data script ready to be passed into OS::Nova::Server  instances. This script turns the parameters\nit receives through Heat into environment variables, clones bootstrap-scripts  and launches initialize_instance  in this environment. Usually\nyou will only need one instance of this resource per Heat stack, i.e. you can\npass the same generated script to all Nova servers in your stack.", 
            "title": "Heat Resource"
        }, 
        {
            "location": "/entry/#autostrapstandalone", 
            "text": "For environments without Heat and cloud-init we developed autostrap.standalone .\nThis script provides the same environment as the AS::autostrap  Heat\nresource and invokes initialize_instance as well. It emulates the Heat based\nparametrization mechanisms detailed in the  Life of a Stack  section with the\nfollowing two mechanisms:    Parameters that are passed into  AS::autostrap  as Heat properties are retrieved from identically named environment variables.    cloud-init metadata parameters are passed as  =  delimited key-value arguments to  autostrap.standalone 's  -m  option.    Example:   autostrap.standalone -m topics=puppet-agent \\\n                      -m nodetype=appserver", 
            "title": "autostrap.standalone"
        }, 
        {
            "location": "/lifecycle/", 
            "text": "Starting Point: A Heat Template\n\n\nFirst Bootstrapping Stage: The AS::autostrap Heat resource\n\n\nSecond Bootstraping Stage: The bootstrap-scripts repository\n\n\nStarting Point: initialize_instance\n\n\nPuppet Setup: Configuration Repository Retrieval\n\n\nPackages and System Setup\n\n\nPuppet Setup: Temporary Module Installation\n\n\nPuppet Setup: Hiera Configuration and Repository Checkouts\n\n\nDisabling the hiera.yaml generator\n\n\nUsing the AS::autostrap Heat Resource\n\n\nUsing cloudstrap.standalone\n\n\n\n\n\n\n\n\n\n\nPuppet Setup: First Puppet Run\n\n\n\n\n\n\n\n\n\n\nIn this section we will describe the life cycle of a Autostrap deployed\nservice stack, from instantiating a heat template to the finished application,\nin particular this includes:\n\n\n\n\n\n\nThe components a Heat template needs for the instances within to be deployed\n  by Autostrap\n\n\n\n\n\n\nThe individual stages in an instance's bootstrapping proces.\n\n\n\n\n\n\nRead this section to get a high-level overview of what happens during the\nAutostrap bootstrapping process and how it is kicked off. You can later\ncomplement it with the \nConfiguration Sources\n section for an in-depth\ndiscussion of the configuration sources that govern Autostrap's behaviour.\n\n\nStarting Point: A Heat Template\n\n\n\n\nOnce a machine is up, cloud-init will execute the user-data script generated by\n\nAS::autostrap\n. This\nscript will install \ngit\n, copy the deploy key to /root/.ssh, and clone\n\nbootstrap-scripts\n. Once\n\nbootstrap-scripts\n is available, the user-data scripts will execute the\n\ninitialize_instance\n script in that repository's top-level directory, ushering\nin the second bootstrapping stage.\nDeployment of a service stack is kicked off by a Heat template. The schematic\nbelow shows the key components of the\n\nnginx-master-agent\n\nexample Heat template and their relation to each other:\n\n\n\n\nThere are two kinds of configuration the heat template passes to the two\ninstances (\npuppetmaster\n and \nnginx-server\n):\n\n\n\n\n\n\nA user-data script. This script is generated by the\n  \nAS::autostrap\n Heat\n  resource and commonly parametrized through Heat. At a minimum, it needs a\n  \nconfig_repo\n parameter pointing at your \nproject-config\n repository.\n  Commonly there is only one \nAS::autostrap\n resource that is passed to all servers in the stack.\n\n\n\n\n\n\ncloud-init\n metadata keys that pass\ninformation for use inside the node and control various aspects of puppet\nconfiguration. The most important such parameter is \ntopics\n. This\nparameter governs the topics from \nglobal-config\n that the\n\nsecond bootstrapping stage's puppet run\n\nwill deploy on the machine in question. In the example this makes\n\npuppetmaster\n a puppet master and agent, and \nnginx-server\n a puppet agent.\n\n\n\n\n\n\nOnce the Heat template is finished it can be deployed with a command that might\nlook roughly as follows:\n\n\nheat stack-create -f nginx-master-agent.yaml \\\n                  -P config_repo=git@gitlab.example.com/my_project_config.git \\\n                  -P key_name=mykey \\\n                  -P deploy_key=\n$(cat ~/.ssh/deploy_key)\n \\\n                  nginx-master-agent\n\n\n\n\nOnce this command is issued, heat will create the stack's constituent\nresources. As machines come up, their \nAS::autostrap\n\ngenerated user-data script will be run by cloud-init. To provide an overview of the bootstrapping\nprocess we will use the following schematic throughout the rest of this\nsection, with the current step highlighted:\n\n\n\n\nFirst Bootstrapping Stage: The AS::autostrap Heat resource\n\n\n\n\nOnce a machine is up, cloud-init will execute the user-data script generated by\n\nAS::autostrap\n. This\nscript will install \ngit\n, copy the deploy key to /root/.ssh, and clone\n\nbootstrap-scripts\n. Once\n\nbootstrap-scripts\n is available, the user-data scripts will execute the\n\ninitialize_instance\n script in that repository's top-level directory, ushering\nin the second bootstrapping stage.\n\n\nSecond Bootstraping Stage: The bootstrap-scripts repository\n\n\nOnce the user-data script has run its course, it executes the script\n\ninitialize_instance\n in the \nboostrap-scripts\n repository it just cloned.\n\n\n\n\nStarting Point: initialize_instance\n\n\n\n\ninitialize_instance\n is primarily a wrapper for starting the various scripts\nin the second bootstrapping stage. It keeps track of progress (and writes\nstatus messages to \n/dev/console\n for outside visibility) and ensures all\nsecond stage output is logged to \n/var/log/initialize_instance.log\n. Once all\nsecond stage scripts have run, \ninitialize_instance\n will report conclusion of\nthe bootstrapping process to \n/dev/console\n.\n\n\nAll second stage bootstrapping scripts are drawn from two sources:\n\n\n\n\n\n\nThe \nbootstrap.d/\n subdirectory of the \nglobal-config\n repository.\n\n\n\n\n\n\nThe \nbootstrap.d/\n subdirectory of your \nproject-config\n repository.\n\n\n\n\n\n\nThe contents of both these directories are symlinked to the\n\n/opt/scripts/stage/\n directory. All files in this directory are executed in\nshell globbing order, i.e. a script named \n000-first\n will be executed before\n111-last (much like in sysvinit's rc*.d directories). All scripts in\n\nglobal-config\n are prefixed with a zero-padded, three digit multiple of 20,\ne.g. \n000-first\n, \n020-second\n, \n040-third\n, ...\n\n\nIf you add any scripts to your \nproject-config\n repository's\n\nbootstrap.d\n directory please do not prefix them with multiples of 20 since\nthese are reserved for scripts from \nglobal-config\n.\nApart from that anything goes. I.e. you can number them in a way that places\nthem between any two scripts from \nglobal-config\n. If,\nfor instance, you wanted your own script to run between \n020-setup_system\n and\n\n040-setup_puppet_modules\n, you could name it \n030-myscript\n.\n\n\nThe rest of this section will give a rundown of the bootstrapping scripts\npulled in from the \nglobal-config\n repository.\n\n\nPuppet Setup: Configuration Repository Retrieval\n\n\n\n\nThe \nsetup_repos\n script clones the two main configuration repositories that combine\ninto the service stack's configuration (\nglobal-config\n and a\n\nproject-config repository\n), as well as the \nrepodeploy\n\npuppet module. The URLs and revisions for these repositories are supplied as environment variables \npassed through from the user-data script.\n\n\nPackages and System Setup\n\n\n\n\nsetup_system\n is the first real step in the second bootstrapping stage. It\nconfigures \napt\n repositories, installs packages required during the second\nbootstrapping stage, and configures various things in a sensible manner. Once\nit has finished, \nPuppet\n setup begins.\n\n\nPuppet Setup: Temporary Module Installation\n\n\n\n\nWith the preliminaries out of the way, \nPuppet\n \ndeployment can now begin in earnest. As a first step, \nsetup_puppet_modules\n\nperforms for puppet what \nsetup_system\n performed for the whole system: it\ninstalls a small selection of Puppet modules into \n/etc/puppet/modules\n. These\nmodules are the bare minimum required for a first run of\n\npuppet-repodeploy\n.\n\n\nPuppet Setup: Hiera Configuration and Repository Checkouts\n\n\n\n\nsetup_hiera\n is the centerpiece of Autostrap's puppet bootstrapping process.\nIt performs two tasks:\n\n\n\n\n\n\nIt generates a \nhiera.yaml\n configuration file. This file contains a list of\n  all the configuration files that are consulted by puppet running on this\n  machine (both in masterless mode, and by a puppet master if this machine\n  happens to be one).\n\n\n\n\n\n\nIt clones the additional configuration repositories specified in the\n  \nadditional_config\n Heat parameter and adds\n  corresponding entries in hiera.yaml.\n\n\n\n\n\n\nIt runs \npuppet-repodeploy\n to retrieve\n  the repositories defined in the \nrepodeploy::repos\n hash. This hash may occur\n  anywhere in the files listed in \nhiera.yaml\n. Multiple occurences are merged.\n\n\n\n\n\n\nThe contents of \nhiera.yaml\n vary based on the following parameters:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe \ncloud-init\n metadata entry \ntopics\n\n\nThis is a space delimited list that determines the topics to be deployed by (a) \nrun_puppet_hiera\n and (b) subsequent puppet runs, if the \npuppet-masterless\n topic has been deployed to this machine. All configuration files that make up the topic in question will be entered in \nhiera.yaml\n.\n\n\n\n\n\n\nThe contents of \npuppet/topics\n in the \nproject-config\n repository\n\n\nThis is mainly relevant for a Puppet master. This file contains a list of all the topics this puppet master serves to its agents. \nsetup_hiera\n will add the contents of these topics' \nconfig.d\n and \nrepos.d\n subdirectories to \nhiera.yaml\n. Thus both the configuration relevant to the topics in question and the puppet modules required for their deployment will be available on the puppet master.\n\n\n\n\n\n\n\n\nOnce \nhiera.yaml\n has been generated and repodeploy has retrieved all\nrepositories, \nsetup_hiera\n will remove \n/etc/puppet/modules\n, since it has\nserved its purpose: the modules therein were only required to run\n\npuppet-repodeploy\n. From this point onward, only puppet modules retrieved by\n\npuppet-repodeploy\n will be used. The system is now ready for its first\nmasterless puppet run.\n\n\nDisabling the \nhiera.yaml\n generator\n\n\nIf you would like to have full control over your \nhiera.yaml\n you can skip this\nstep by passing a path to your own hiera.yaml through the \nhiera_yaml_location\n\nmetadata parameter.\n\n\nIf you specify this path, you are responsible for ensuring the file thus\nreferenced exists on your system (we recommend putting it into your\nproject-config repository which is cloned to \n/opt/config/project\n.\n\n\nNote: while there is no warranty to void, this will lose you most Autostrap\nfeatures: all you will get is an environment that runs puppet driven by the\nhiera.yaml you provided at the end of the bootstrapping process.\n\n\nIf you chose to do this, there are two ways to pass the \nhiera_yaml_location\n\nparameter, depending on how you run Autostrap:\n\n\nUsing the AS::autostrap Heat Resource\n\n\nIf you are using \nHeat\n you can specify this parameter\nas part of your instance's \nmetadata\n hash:\n\n\nserver:\n  type: OS::Nova::Server\n  properties:\n    name: myserver\n    metadata:\n      hiera_yaml_location: '/opt/config/project/puppet/hiera.yaml'\n\n\n\n\nUsing cloudstrap.standalone\n\n\nIf you are using \nautostrap.standalone\n to start\nthe bootstrapping process you can specify this parameter by adding a \n-m\n\noption:\n\n\nautostrap.standalone -m hiera_yaml_location=/opt/config/project/puppet/hiera.yaml\n\n\n\n\n\n\nPuppet Setup: First Puppet Run\n\n\n\n\nAt the end of the puppet bootstrapping process, \nrun_puppet_hiera\n will run\npuppet, driven by the \nhiera.yaml\n just generated. This puppet run will deploy\nall \ntopics\n listed in the machine's \ntopics\n metadata entry. This list\nusually includes either \npuppet-masterless\n or \npuppet-agent\n. Hence this first\npuppet run ensures continuing management of the machine's configuration by\nregular puppet runs from now on.", 
            "title": "Life of a Stack"
        }, 
        {
            "location": "/lifecycle/#starting-point-a-heat-template", 
            "text": "Once a machine is up, cloud-init will execute the user-data script generated by AS::autostrap . This\nscript will install  git , copy the deploy key to /root/.ssh, and clone bootstrap-scripts . Once bootstrap-scripts  is available, the user-data scripts will execute the initialize_instance  script in that repository's top-level directory, ushering\nin the second bootstrapping stage.\nDeployment of a service stack is kicked off by a Heat template. The schematic\nbelow shows the key components of the nginx-master-agent \nexample Heat template and their relation to each other:   There are two kinds of configuration the heat template passes to the two\ninstances ( puppetmaster  and  nginx-server ):    A user-data script. This script is generated by the\n   AS::autostrap  Heat\n  resource and commonly parametrized through Heat. At a minimum, it needs a\n   config_repo  parameter pointing at your  project-config  repository.\n  Commonly there is only one  AS::autostrap  resource that is passed to all servers in the stack.    cloud-init  metadata keys that pass\ninformation for use inside the node and control various aspects of puppet\nconfiguration. The most important such parameter is  topics . This\nparameter governs the topics from  global-config  that the second bootstrapping stage's puppet run \nwill deploy on the machine in question. In the example this makes puppetmaster  a puppet master and agent, and  nginx-server  a puppet agent.    Once the Heat template is finished it can be deployed with a command that might\nlook roughly as follows:  heat stack-create -f nginx-master-agent.yaml \\\n                  -P config_repo=git@gitlab.example.com/my_project_config.git \\\n                  -P key_name=mykey \\\n                  -P deploy_key= $(cat ~/.ssh/deploy_key)  \\\n                  nginx-master-agent  Once this command is issued, heat will create the stack's constituent\nresources. As machines come up, their  AS::autostrap \ngenerated user-data script will be run by cloud-init. To provide an overview of the bootstrapping\nprocess we will use the following schematic throughout the rest of this\nsection, with the current step highlighted:", 
            "title": "Starting Point: A Heat Template"
        }, 
        {
            "location": "/lifecycle/#first-bootstrapping-stage-the-asautostrap-heat-resource", 
            "text": "Once a machine is up, cloud-init will execute the user-data script generated by AS::autostrap . This\nscript will install  git , copy the deploy key to /root/.ssh, and clone bootstrap-scripts . Once bootstrap-scripts  is available, the user-data scripts will execute the initialize_instance  script in that repository's top-level directory, ushering\nin the second bootstrapping stage.", 
            "title": "First Bootstrapping Stage: The AS::autostrap Heat resource"
        }, 
        {
            "location": "/lifecycle/#second-bootstraping-stage-the-bootstrap-scripts-repository", 
            "text": "Once the user-data script has run its course, it executes the script initialize_instance  in the  boostrap-scripts  repository it just cloned.", 
            "title": "Second Bootstraping Stage: The bootstrap-scripts repository"
        }, 
        {
            "location": "/lifecycle/#starting-point-initialize_instance", 
            "text": "initialize_instance  is primarily a wrapper for starting the various scripts\nin the second bootstrapping stage. It keeps track of progress (and writes\nstatus messages to  /dev/console  for outside visibility) and ensures all\nsecond stage output is logged to  /var/log/initialize_instance.log . Once all\nsecond stage scripts have run,  initialize_instance  will report conclusion of\nthe bootstrapping process to  /dev/console .  All second stage bootstrapping scripts are drawn from two sources:    The  bootstrap.d/  subdirectory of the  global-config  repository.    The  bootstrap.d/  subdirectory of your  project-config  repository.    The contents of both these directories are symlinked to the /opt/scripts/stage/  directory. All files in this directory are executed in\nshell globbing order, i.e. a script named  000-first  will be executed before\n111-last (much like in sysvinit's rc*.d directories). All scripts in global-config  are prefixed with a zero-padded, three digit multiple of 20,\ne.g.  000-first ,  020-second ,  040-third , ...  If you add any scripts to your  project-config  repository's bootstrap.d  directory please do not prefix them with multiples of 20 since\nthese are reserved for scripts from  global-config .\nApart from that anything goes. I.e. you can number them in a way that places\nthem between any two scripts from  global-config . If,\nfor instance, you wanted your own script to run between  020-setup_system  and 040-setup_puppet_modules , you could name it  030-myscript .  The rest of this section will give a rundown of the bootstrapping scripts\npulled in from the  global-config  repository.", 
            "title": "Starting Point: initialize_instance"
        }, 
        {
            "location": "/lifecycle/#puppet-setup-configuration-repository-retrieval", 
            "text": "The  setup_repos  script clones the two main configuration repositories that combine\ninto the service stack's configuration ( global-config  and a project-config repository ), as well as the  repodeploy \npuppet module. The URLs and revisions for these repositories are supplied as environment variables \npassed through from the user-data script.", 
            "title": "Puppet Setup: Configuration Repository Retrieval"
        }, 
        {
            "location": "/lifecycle/#packages-and-system-setup", 
            "text": "setup_system  is the first real step in the second bootstrapping stage. It\nconfigures  apt  repositories, installs packages required during the second\nbootstrapping stage, and configures various things in a sensible manner. Once\nit has finished,  Puppet  setup begins.", 
            "title": "Packages and System Setup"
        }, 
        {
            "location": "/lifecycle/#puppet-setup-temporary-module-installation", 
            "text": "With the preliminaries out of the way,  Puppet  \ndeployment can now begin in earnest. As a first step,  setup_puppet_modules \nperforms for puppet what  setup_system  performed for the whole system: it\ninstalls a small selection of Puppet modules into  /etc/puppet/modules . These\nmodules are the bare minimum required for a first run of puppet-repodeploy .", 
            "title": "Puppet Setup: Temporary Module Installation"
        }, 
        {
            "location": "/lifecycle/#puppet-setup-hiera-configuration-and-repository-checkouts", 
            "text": "setup_hiera  is the centerpiece of Autostrap's puppet bootstrapping process.\nIt performs two tasks:    It generates a  hiera.yaml  configuration file. This file contains a list of\n  all the configuration files that are consulted by puppet running on this\n  machine (both in masterless mode, and by a puppet master if this machine\n  happens to be one).    It clones the additional configuration repositories specified in the\n   additional_config  Heat parameter and adds\n  corresponding entries in hiera.yaml.    It runs  puppet-repodeploy  to retrieve\n  the repositories defined in the  repodeploy::repos  hash. This hash may occur\n  anywhere in the files listed in  hiera.yaml . Multiple occurences are merged.    The contents of  hiera.yaml  vary based on the following parameters:           The  cloud-init  metadata entry  topics  This is a space delimited list that determines the topics to be deployed by (a)  run_puppet_hiera  and (b) subsequent puppet runs, if the  puppet-masterless  topic has been deployed to this machine. All configuration files that make up the topic in question will be entered in  hiera.yaml .    The contents of  puppet/topics  in the  project-config  repository  This is mainly relevant for a Puppet master. This file contains a list of all the topics this puppet master serves to its agents.  setup_hiera  will add the contents of these topics'  config.d  and  repos.d  subdirectories to  hiera.yaml . Thus both the configuration relevant to the topics in question and the puppet modules required for their deployment will be available on the puppet master.     Once  hiera.yaml  has been generated and repodeploy has retrieved all\nrepositories,  setup_hiera  will remove  /etc/puppet/modules , since it has\nserved its purpose: the modules therein were only required to run puppet-repodeploy . From this point onward, only puppet modules retrieved by puppet-repodeploy  will be used. The system is now ready for its first\nmasterless puppet run.  Disabling the  hiera.yaml  generator  If you would like to have full control over your  hiera.yaml  you can skip this\nstep by passing a path to your own hiera.yaml through the  hiera_yaml_location \nmetadata parameter.  If you specify this path, you are responsible for ensuring the file thus\nreferenced exists on your system (we recommend putting it into your\nproject-config repository which is cloned to  /opt/config/project .  Note: while there is no warranty to void, this will lose you most Autostrap\nfeatures: all you will get is an environment that runs puppet driven by the\nhiera.yaml you provided at the end of the bootstrapping process.  If you chose to do this, there are two ways to pass the  hiera_yaml_location \nparameter, depending on how you run Autostrap:  Using the AS::autostrap Heat Resource  If you are using  Heat  you can specify this parameter\nas part of your instance's  metadata  hash:  server:\n  type: OS::Nova::Server\n  properties:\n    name: myserver\n    metadata:\n      hiera_yaml_location: '/opt/config/project/puppet/hiera.yaml'  Using cloudstrap.standalone  If you are using  autostrap.standalone  to start\nthe bootstrapping process you can specify this parameter by adding a  -m \noption:  autostrap.standalone -m hiera_yaml_location=/opt/config/project/puppet/hiera.yaml", 
            "title": "Puppet Setup: Hiera Configuration and Repository Checkouts"
        }, 
        {
            "location": "/lifecycle/#puppet-setup-first-puppet-run", 
            "text": "At the end of the puppet bootstrapping process,  run_puppet_hiera  will run\npuppet, driven by the  hiera.yaml  just generated. This puppet run will deploy\nall  topics  listed in the machine's  topics  metadata entry. This list\nusually includes either  puppet-masterless  or  puppet-agent . Hence this first\npuppet run ensures continuing management of the machine's configuration by\nregular puppet runs from now on.", 
            "title": "Puppet Setup: First Puppet Run"
        }, 
        {
            "location": "/config/", 
            "text": "Configuration Sources\n\n\nglobal-config: Default Configuration\n\n\nProject Configuration\n\n\nAdditional Configuration\n\n\nadditional_config Parameter Format\n\n\nadditional_config Example\n\n\nEntry Position in hiera.yaml\n\n\n\n\n\n\ncloud-init: User Data Script and Metadata Parameters\n\n\ncloud-init user-data script\n\n\n\n\n\n\ncloud-init metadata parameters\n\n\n\n\n\n\n\n\n\n\n\n\nMachines deployed through Autostrap draw their configuration from various\nsources. The schematic above shows a big-picture view of these sources and how\nthey interact with each other. In this section we will discuss the four sources\nfor configuration information Autostrap uses: \n\n\n\n\nDefault configuration from \nglobal-config\n\n\nproject specific configuration from a \nproject-config\n\n  repository\n\n\nAdditional user specified configuration repositories\n\n\ncloud-init\n user-data and metadata.\n\n\n\n\nRead this section to get an in-depth tour of the configuration sources at your\ndisposal. If you are itching to try Autostrap you can skip this section. Just\ncreate a private fork of \nproject-config\n and\nmove on to the \nDeployment Workflow\n section.\n\n\nConfiguration Sources\n\n\n\n\nglobal-config: Default Configuration\n\n\nThe repository \nglobal-config\n contains\ncollections of Puppet classes along with matching\n\nHiera\n configuration to deploy on Openstack\ninstances. We refer to these collections as \ntopics\n). Topics can\nbe deployed to instances in two ways: directly, using the \ntopics\n\nmetadata parameter, or indirectly by\n\nintegrating\n them in a\n\nproject-config\n repository.\n\n\nThe \nglobal-config\n repository is meant as default configuration, to be overriden and extended\nby the \nproject-config\n repository described in the next\nsection.\n\n\n\n\nProject Configuration\n\n\nThe second pilar of configuration is the \nproject-config\n repository. \nThis is where a Autostrap user will store most of their configuration. Since a\nfair amount of configuration is provided by global-config, this repository's\nconfiguration payload can be fairly small. For instance, the [project\nconfiguration content][ex::docserver] required to set up a web server building and serving this\ndocumentation consists of 69 lines at the time of this writing.\n\n\nUsually a \nproject-config\n repository starts out as a fork of Autostrap's\n\nexample project-config repository\n. We\nrecommend you store this fork in a private Git repository which is accessible\nwith an SSH deploy key provided to machines using the \ndeploy_key\n parameter of\nthe \nAS::autostrap Heat resource\n.\nThe \nproject-config\n repository's URL and revision are specified\nthrough the \nconfig_repo\n\nand \nconfig_branch\n\nparameters to the\n\nAS::autostrap Heat resource\n, respectively.\n\n\n\n\nAdditional Configuration\n\n\nFinally, autostrap contains a mechanism for inserting arbitrary snippets of\nHiera configuration. This mechanism is controlled through the\n\nAS::autostrap Heat resource's \nadditional_config\n parameter\n\nwhich contains a space delimited list of git repositories. These repositories\nare cloned during bootstrapping, and entries in hiera.yaml referencing them are\ngenerated.\n\n\nadditional_config Parameter Format\n\n\nEntries in the list of repositories are formatted as follows:\n\n\nrepository url\n[#\nrevision\n]::[[\npath\n][:\npath\n ...]]\n\n\n\n\nAn entry consists of the following components:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrepository url\n\n\nThe Repository's  URL (mandatory).\n\n\n\n\n\n\nrevision\n\n\nA revision (branch or commit ID) of the repository to check out (optional).\n\n\n\n\n\n\npath\n\n\nA path referencing a YAML file (the .yaml extension may be omitted), relative to the repository's root directory. Each of these paths will result in an entry in hiera.yaml. There may be multiple paths, separated by colons as in a \n$PATH\n variable. Paths my include shell wildcards (\n*\n, \n?\n, etc.) which will be expanded.\n\n\n\n\n\n\n\n\nadditional_config Example\n\n\nThis is what the contents of an \nadditional_config\n parameter might look like: \n\n\n'https://example.com/my-additional-config.git::ssh/mykeys.yaml \\\ngit@gitlab.example.com:my-team/my-config.git#devel::config/ssh/keys:apache/*'\n\n\n\n\nThis will trigger the following actions:\n\n\n\n\nClone \nhttps://example.com/my-additional-config.git\n and symlink it to \n/etc/puppet/hieradata/my-additional-config\n.\n\n\nAdd \nmy-additional-config/ssh/mykeys\n to Hiera's hierarchy.\n\n\nClone \ngit@gitlab.example.com:my-team/my-config.git\n, checkout revision \ndevel\n and symlink it to \n/etc/puppet/hieradata/my-team\n.\n\n\nAdd \nmy-team/ssh/keys\n, and all contents of the \napache/\n subdirectory to Hiera's hierarchy.\n\n\n\n\nEntry Position in hiera.yaml\n\n\nHierarchy entries resulting from the \nadditional_config\n parameter will appear\nbefore entries from the \nproject-config\n repository.\n\n\nRepositories will appear in the order their repository specifications appear in\n\nadditional_config\n.\n\n\nPaths associated with a given repository will appear in the order they were\ngiven in the repository's \nadditional_config\n entry.\n\n\ncloud-init: User Data Script and Metadata Parameters\n\n\nLast, but not least, \ncloud-init\n, is the glue that binds the\nother two configuration sources together. It is used in two ways: to inject a\nuser-data script into an instance and to pass so-called 'metadata', a set of\nkey-value parameters. The user-data script kicks off the bootstrapping process,\nthe metadata parameters influence its behaviour.\n\n\ncloud-init user-data script\n\n\nThe user-data script generated by \nAS::autostrap\n \nis parametrized by its parent heat template and passed to to all servers in a\nservice stack. Through this mechanism the servers receive their deploy keys\nand their configuration repositories' URLs. This script is usually generated\nonce per service stack and passed to all machines unchanged.\n\n\nOne notable parameter to this script is\n\noverride_yaml\n. It contains\nthe contents of \noverride.yaml\n, a file that will appear at the very top of\nthe machine's \nhiera.yaml\n and override all other configuration. This\nmechanism is very useful for deploying development stacks based off one or\nmore development branches, or for any other temporary configuration you don't\nwant to commit to your project-config repository.\n\n\nIf you require additional high-level entries, for instance to pull in passwords\nautomatically generated by your bootstraping scripts, you can use the\n\nextra_overrides\n parameter to\nadd arbitrary hierarchy entries between \noverride.yaml\n and\n\nadditional-config\n/\nproject-config\n.\n\n\ncloud-init metadata parameters\n\n\nVarious \ncloud-init\n metadata paremeters influence the behaviour of puppet,\npass information (such as its floating IP address), or control the\n\ntopics\n deployed on a given machine. Metadata parameters can\nvary on a per-machine basis (e.g. typically only one machine will be assigned\nthe \npuppet-master\n topic while all others are assigned the \npuppet-agent\n\ntopic).", 
            "title": "Configuration Sources"
        }, 
        {
            "location": "/config/#configuration-sources", 
            "text": "", 
            "title": "Configuration Sources"
        }, 
        {
            "location": "/config/#global-config-default-configuration", 
            "text": "The repository  global-config  contains\ncollections of Puppet classes along with matching Hiera  configuration to deploy on Openstack\ninstances. We refer to these collections as  topics ). Topics can\nbe deployed to instances in two ways: directly, using the  topics \nmetadata parameter, or indirectly by integrating  them in a project-config  repository.  The  global-config  repository is meant as default configuration, to be overriden and extended\nby the  project-config  repository described in the next\nsection.", 
            "title": "global-config: Default Configuration"
        }, 
        {
            "location": "/config/#project-configuration", 
            "text": "The second pilar of configuration is the  project-config  repository. \nThis is where a Autostrap user will store most of their configuration. Since a\nfair amount of configuration is provided by global-config, this repository's\nconfiguration payload can be fairly small. For instance, the [project\nconfiguration content][ex::docserver] required to set up a web server building and serving this\ndocumentation consists of 69 lines at the time of this writing.  Usually a  project-config  repository starts out as a fork of Autostrap's example project-config repository . We\nrecommend you store this fork in a private Git repository which is accessible\nwith an SSH deploy key provided to machines using the  deploy_key  parameter of\nthe  AS::autostrap Heat resource .\nThe  project-config  repository's URL and revision are specified\nthrough the  config_repo \nand  config_branch \nparameters to the AS::autostrap Heat resource , respectively.", 
            "title": "Project Configuration"
        }, 
        {
            "location": "/config/#additional-configuration", 
            "text": "Finally, autostrap contains a mechanism for inserting arbitrary snippets of\nHiera configuration. This mechanism is controlled through the AS::autostrap Heat resource's  additional_config  parameter \nwhich contains a space delimited list of git repositories. These repositories\nare cloned during bootstrapping, and entries in hiera.yaml referencing them are\ngenerated.  additional_config Parameter Format  Entries in the list of repositories are formatted as follows:  repository url [# revision ]::[[ path ][: path  ...]]  An entry consists of the following components:           repository url  The Repository's  URL (mandatory).    revision  A revision (branch or commit ID) of the repository to check out (optional).    path  A path referencing a YAML file (the .yaml extension may be omitted), relative to the repository's root directory. Each of these paths will result in an entry in hiera.yaml. There may be multiple paths, separated by colons as in a  $PATH  variable. Paths my include shell wildcards ( * ,  ? , etc.) which will be expanded.     additional_config Example  This is what the contents of an  additional_config  parameter might look like:   'https://example.com/my-additional-config.git::ssh/mykeys.yaml \\\ngit@gitlab.example.com:my-team/my-config.git#devel::config/ssh/keys:apache/*'  This will trigger the following actions:   Clone  https://example.com/my-additional-config.git  and symlink it to  /etc/puppet/hieradata/my-additional-config .  Add  my-additional-config/ssh/mykeys  to Hiera's hierarchy.  Clone  git@gitlab.example.com:my-team/my-config.git , checkout revision  devel  and symlink it to  /etc/puppet/hieradata/my-team .  Add  my-team/ssh/keys , and all contents of the  apache/  subdirectory to Hiera's hierarchy.   Entry Position in hiera.yaml  Hierarchy entries resulting from the  additional_config  parameter will appear\nbefore entries from the  project-config  repository.  Repositories will appear in the order their repository specifications appear in additional_config .  Paths associated with a given repository will appear in the order they were\ngiven in the repository's  additional_config  entry.", 
            "title": "Additional Configuration"
        }, 
        {
            "location": "/config/#cloud-init-user-data-script-and-metadata-parameters", 
            "text": "Last, but not least,  cloud-init , is the glue that binds the\nother two configuration sources together. It is used in two ways: to inject a\nuser-data script into an instance and to pass so-called 'metadata', a set of\nkey-value parameters. The user-data script kicks off the bootstrapping process,\nthe metadata parameters influence its behaviour.  cloud-init user-data script  The user-data script generated by  AS::autostrap  \nis parametrized by its parent heat template and passed to to all servers in a\nservice stack. Through this mechanism the servers receive their deploy keys\nand their configuration repositories' URLs. This script is usually generated\nonce per service stack and passed to all machines unchanged.  One notable parameter to this script is override_yaml . It contains\nthe contents of  override.yaml , a file that will appear at the very top of\nthe machine's  hiera.yaml  and override all other configuration. This\nmechanism is very useful for deploying development stacks based off one or\nmore development branches, or for any other temporary configuration you don't\nwant to commit to your project-config repository.  If you require additional high-level entries, for instance to pull in passwords\nautomatically generated by your bootstraping scripts, you can use the extra_overrides  parameter to\nadd arbitrary hierarchy entries between  override.yaml  and additional-config / project-config .", 
            "title": "cloud-init: User Data Script and Metadata Parameters"
        }, 
        {
            "location": "/config/#cloud-init-metadata-parameters", 
            "text": "Various  cloud-init  metadata paremeters influence the behaviour of puppet,\npass information (such as its floating IP address), or control the topics  deployed on a given machine. Metadata parameters can\nvary on a per-machine basis (e.g. typically only one machine will be assigned\nthe  puppet-master  topic while all others are assigned the  puppet-agent \ntopic).", 
            "title": "cloud-init metadata parameters"
        }, 
        {
            "location": "/workflow/", 
            "text": "In this section we will describe deployment workflows for two kinds of\nPuppet configuration approaches: masterless Puppet (for single-instance stacks)\nand a traditional Puppet master/agent setup (for stacks of two or more\ninstances). Both approaches follow the same basic basic steps:\n\n\n\n\nThese workflows assume you are deploying to an Openstack cloud, but they can be\nadapted to \nautostrap.standalone\n if you do not\nhave access to an Openstack cloud.\n\n\nWe will start this section off with a check list of common prerequisites you\nwill need for both approaches. Once you have the items on this list covered you\ncan dive right into deploying your first stack using either the\n\nmaster/agent\n or \nmasterless\n\napproach.\n\n\nPrerequisites\n\n\nFollowing the deployment instructions described in this section requires the following:\n\n\n\n\nA user account on an Openstack cloud\n\n\nThe Openstack \ncommand-line clients\n\n\ngit\n\n\nA remotely accessible (e.g. through SSH or HTTPS) git repository for storing\n  project specific configuration. This repository should start out as a fork of\n  Autostrap's \nsample project-config repository\n. Throughout this section we will\n  refer to this repository with the placeholder \nmy-config\n and to its url with\n  the placeholder \nmy-config-url\n.\n\n\nAn editor with syntax highlighting for \nYAML\n (optional, but recommended)\n\n\nThe syseleven.cloudutils package for smoother handling of heat stacks\n  (optional, but recommended). A simple \npip install syseleven.cloudutils\n\n  should take care of this.\n\n\n\n\n\n\nPuppet Master/Agent Based Configuration\n\n\nFor larger setups a Puppet master can be automatically deployed, with all nodes\n(including the Puppet master itself) running Puppet agents. This approach is\nrecommended for any setup beyond two nodes. This approach consists of a\nmasterless first stage that sets up the Puppet master and its agent, with\nconfiguration being provided through the Puppet master from there on out.\n\n\nStep 1: Creating a Heat Template\n\n\nFirst of all you will need to describe your projects requirements in terms of a\nHeat template. As a starting point, the Heat project provides some \n\nguidelines\n\non writing heat templates.\n\n\nAutostrap requires various meta data parameters and its own user-data script,\nso we recommend you modify one of our example templates in the \nheat-templates\n\ndirectory of \nproject-config\n to fit your project's\nrequirements.\n\n\nAdding a AS::autostrap resource\n\n\nThe custom Heat resource \nAS::autostrap\n generates a user-data script that\nwill kick off the autostrap deployment process. This user-data script is then\npassed to your instances (\nOS::Nova::Server\n resources) as user-data property.\n\n\nProperties\n\n\nThe following properties of \nAS::autostrap\n are most likely to be relevant\nto deploying a new project (refer to the \nAS::autostrap\n documentation for\nthe rest):\n\n\n\n\n\n\nconfig_repo\n: The URL of your project specific configuration repository, i.e.\n  \nmy-config-url\n.\n\n\n\n\n\n\nconfig_branch\n: An optional branch/revision of your configuration repository\n  to check out. This is mainly useful for development and best sourced from a\n  Heat parameter that defaults to 'master' (thus allowing you to specify\n  experimental/development branches at run-time, while defaulting to a\n  known-good stable branch otherwise).'\n\n\n\n\n\n\ndeploy_key\n: A SSH private key with access to all non-public repositories\n  you specified in your repository configuration (i.e. all instances of\n  \nrepodeploy::repos\n occuring in your configuration). We strongly recommend\n  against adding this deploy key to your heat template. Current best practice\n  is to pass it as a parameter (with the \nhidden\n attribute enabled). \n\n\n\n\n\n\nDeclaration Example\n\n\n  bootstrap:\n      type: AS::autostrap::v1\n      properties:\n        deploy_key: { get_param: deploy_key }\n        config_repo: \nmy-config-url\n\n        config_branch: \n\n\n\n\nInstance Attachment Example\n\n\n  my_machine:\n    type: OS::Nova::Server\n      properties:\n        name: my_machine\n        user_data: { get_attr: [ bootstrap, script ] }\n        user_data_format: RAW\n\n\n\n\nNote the \"::v1\" trailing the resource declaration. Like all of Autostrap's\ncustom resources, this resource is versioned: whenever we introduce breaking\nAPI changes we increment the version number. This way you can generally rely on\na given version continuing to behave as as expected. \n\n\nRequired Metadata parameters for instances\n\n\nYou will need to pass at least the following heat parameters to instances\n(\nOS::Nova::Server\n resources) to be deployed using Autostrap:\n\n\n\n\ntopics\n - The configuration topics to deploy on the instance in question\n  (see \nAdding Topics to the Puppet Master\n).\n\n\n\n\nAdditionally, it is recommended to set the following metadata parameters:\n\n\n\n\n\n\nstack_name\n - Available to puppet through the fact \nopenstack_stack_name\n\n  (requires the puppet module openstackfacts)\n\n\n\n\n\n\nfloating_ip\n - Available to puppet through the fact \nopenstack_floating_ip\n\n  (requires the puppet module openstackfacts)\n\n\n\n\n\n\nIf you have followed the recommendations above, a regular machine's metadata property\nmight look as follows:\n\n\n      metadata:\n        stack_name: { get_param: 'OS::stack_name' }\n          topics: \nbase ssh puppet-master-agent\n\n          stack_name: { get_param: 'OS::stack_name' }\n          floating_ip: { get_attr: [ my_port, floating_ip_address ] }\n          topics: \nbase ssh puppet-master-agent\n\n\n\n\n\nThe puppetmaster's metadata property might then look like this:\n\n\n      metadata:\n        stack_name: { get_param: 'OS::stack_name' }\n          topics: \nbase ssh puppet-master-agent\n\n          stack_name: { get_param: 'OS::stack_name' }\n          floating_ip: { get_attr: [ my_port, floating_ip_address ] }\n          topics: \nbase ssh puppet-master-agent\n\n\n\n\n\nStep 2: Adding Configuration Topics From global-config \n\n\nNow you will have to pick configuration \ntopics\n to deploy from\n\nglobal-config\n. Each topic consists of\na set of puppet classes required to deploy the service or other configuration\nit deploys, hiera configuration and a list of repositories containing the\npuppet modules it uses.\n\n\nAt a minimum, you will need the \npuppet-master\n topic on the designated puppet\nmaster and the \npuppet-agent\n topic on all nodes (including the puppet master).\nAdditionally, \nbase\n (sensible configuration and useful packages) and \nssh\n\n(sensible sshd configuration and rollout of ssh public keys) are highly\nrecommended.\n\n\nOnce you have picked topics, edit your heat template and add them to the\n\ntopics\n metadata entry of the instances they are to be deployed on. This\nmetadata entry is a simple space separated list. If we assume you picked all\ntopics recommended in the previous paragraph, a machine's meta data would contain\nthe following entry:\n\n\n      metadata:\n        topics: \nbase ssh puppet-master-agent\n\n\n\n\n\nStep 3: Adding Topics to the Puppet Master \n\n\nThe \nconfiguration topics\n you picked in the previous section\nwill be deployed in a masterless fashion upon node initialization. In addition\nto these you can and should now pick topics from\n\nglobal-config\n to be available through\nthe puppet master. To this end, simply add their topic names (each on a single\nline) to the \npuppet/topics\n file in the \nmy-config\n repository. These\ntopics' \nconfig.d\n and \nrepos.d\n subdirectories will be included in the puppet\nmasters Hiera hierarchy, making the topics' configuration available and causing\nits component puppet modules to be checked out on the puppet master. Declaring\nthese topics' component classes for individual nodes or node types will be up to you\n(see the next section).\n\n\nStep 4: Forking and Customizing project-config\n\n\nSince you probably want to add custom configuration of your own beyond that\nprovided by \nglobal-config\n, you will\nnow need to fork \nproject-config\n).\nThis fork is the repository we referred to as \nmy-config\n in the\n\nPrerequisites\n section above.\n\n\nControlling access to \nmy-config\n\n\nmy-config\n must be reachable from the Internet, so your Openstack instances\ncan use it to retrieve your projects's configuration. It can be reachable\nthrough a public HTTPS URL, but we strongly recommend to make it accessible\nthrough SSH with public-key authentication. \n\n\nIf you do make \nmy-config\n non-public you will have to supply a\n\ndeploy_key\n property to your\n\nAS::autostrap\n resource. This property must contain a SSH private key that\ncan access \nmy-config\n.\n\n\nCustomizing \nmy-config\n\n\nNow you can modify \nmy-config\n to your heart's content. The changes and\nadditions will then be deployed on your heat stack's machines. You can put\nHiera configuration into the following subdirectories of \nmy-config\n:\n\n\n\n\n\n\npuppet/hieradata/config.d\n: This directory contains hiera configuration\n  relevant to all nodes/node types. It should contain all configuration that is\n  not confined to any specific node or node type. One example for such a\n  configuration value would be the list of SSH authorized keys, configured\n  in the \nssh::keys\n hash. File and directory names in this directory are\n  free-form (every file with a .yaml extension will be included), but it is\n  recommended to organize configuration by topic name for easier navigation by\n  developers.\n\n\n\n\n\n\npuppet/hieradata/repos.d\n: This directory contains \npuppet-repodeploy\n\n  configuration, i.e. zero or more instances of the \nrepodeploy::repos\n hash.\n  This hash specifies repositories to be checked out by \npuppet-repodeploy\n. File\n  and directory names in this directory are free-form (every file with a .yaml\n  extension will be included), but it is recommended to organize configuration\n  by topic name for easier navigation by developers.\n\n\n\n\n\n\npuppet/hieradata/nodes.d\n: This directory contains node specific\n  configuration. It should only contain configuration that is relevant to\n  specific nodes. All file names in this directory must be the target node's\n  FQDN plus a '.yaml' extension, e.g. \npuppetmaster.local.yaml\n. All nodes\n  start out with a FQDN of 'hostname'.local. The \nclasses\n array holding the\n  classes to be deployed on a given node should be defined here.\n\n\n\n\n\n\npuppet/hieradata/nodetypes.d\n: This directory contains node type specific\n  configuration. A node's node type (such as \nappserver\n) is assigned by\n  setting the \nnodetype\n metadata entry. All file names in this directory must\n  be the target node type's name as given in the \nnodetype\n metadata entry,\n  plus a '.yaml' extension, e.g. \nappserver.yaml\n. The \nclasses\n array holding\n  the classes to be deployed on a given node type should be defined here.\n\n\n\n\n\n\nRefer to the  example project-config repository's \nREADME.md file\n\nfile for more detailed information on these directories and their contents.\n\n\nConfiguring classes to be deployed on nodes and node types \n\n\nAll classes to be included in the puppet master's catalog should be declared\neither on a per-node or a per-nodetype basis, i.e. in\n\npuppet/hieradata/nodes.d\n or \npuppet/hieradata/nodetypes.d\n, respectively. If\nyou wish to deploy one or more of the ready-made topics from \nglobal-config\n,\nfor a given node or node type you will need to do two things:\n\n\n\n\n\n\nEnsure the topics' configuration and component puppet modules are available\n   on the puppet master (see \nAdding Topics to the Puppet Master\n).\n\n\n\n\n\n\nAdd the topics' classes to your nodes' and/or nodetypes' classes arrays.\n\n\n\n\n\n\nFor the latter step you can use the \nmerge_classes\n script from the\n\nautostrap-utils\n repository.\nThis script will gather multiple topics' classes arrays from \nglobal-config\n\nand merge them into a classes array ready for inclusion in a configuration file\nin \nnodes.d\n or \nnodetypes.d\n. The following example generates a classes array\ncontaining the \nnginx-server\n, and \npuppet-agent\n topics:\n\n\ngit clone https://github.com/autostrap/global-config.git /tmp/global-config\nmerge_classes --classes-dir /tmp/global-config/puppet/hieradata/classes.d \\\n              nginx-server puppet-agent\n\n\n\n\nThis would yield the following classes array, which also happens to be a valid\nnode/node type configuration:\n\n\nclasses:\n  - \nnginx\n\n  - \nautopuppet::role::agent\n\n\n\n\n\nTo include it in an existing node configuration you would have to remove the\n\n---\n in the first line, since leaving it in place would indicate the begin of\na new YAML document.\n\n\nStep 5: Deploying From Your Heat Template\n\n\nOnce configuration is finished and pushed to the \nmy-config\n repository and\nyour heat template contains the neccessary elements you can deploy a heat stack\nroughly as follows\n\n\nheat stack-create -f mycloud.yaml \\\n                  -P key_name=\nnova key name\n \\\n                  -P deploy_key=\n$(cat ~/.ssh/deploy_key)\n \\\n                  my-master-agent-stack\n\n\n\n\nSubstitute the key name you specified when uploading your SSH key to nova for\n\nnova key name\n.  You may also have to supply a \npublic_net_id\n parameter.\n\n\nOther parameters supplied to \nheat stack-create\n may vary. This example assumes a\nlargely unmodified copy of the \nsensu-master-agent.yaml\n example template with\njust the \nconfig_repo\n parameter's default changed to \nmy-config-url\n.\n\n\n\n\nMasterless Puppet Configuration\n\n\nThis approach is meant for small setups that typically consist of only one or\ntwo servers. In this case a Puppet master is not really needed. Consequently,\nall configuration and Puppet modules relevant to the node in question will be\nlocally available on any node. A cronjob will run puppet locally on a regular\nbasis. The diagram below gives an overview of the steps involved in a\nmasterless puppet setup:\n\n\nStep 1: Creating a Heat Template\n\n\nFirst of all you will need to describe your projects requirements in terms of a\nHeat template. As a starting point, the Heat project provides some \n\nguidelines\n\non writing heat templates.\n\n\nAutostrap requires various meta data parameters and an Autostrap provided\nuser-data script, so we recommend you modify one of our example templates in\nthe heat-templates directory of \nproject-config\n\nto fit your project's requirements.\n\n\nAdding a AS::autostrap resource\n\n\nThe custom Heat resource \nAS::autostrap\n generates a user-data script that\nwill kick off the autostrap deployment process. This user-data script is then\npassed to your instances (\nOS::Nova::Server\n resources) as user-data property.\n\n\nProperties\n\n\nThe following properties of \nAS::autostrap\n are most likely to be relevant\nto deploying a new project (refer to the \nAS::autostrap\n documentation for\nthe rest):\n\n\n\n\n\n\nconfig_repo\n: The URL of your project specific configuration repository, i.e.\n  \nmy-config-url\n. \n\n\n\n\n\n\nconfig_branch\n: An optional branch/revision of your configuration repository\n  to check out. This is mainly useful for development and best sourced from a\n  Heat parameter that defaults to 'master' (thus allowing you to specify\n  experimental/development branches at run-time, while defaulting to a\n  known-good stable branch otherwise).'\n\n\n\n\n\n\ndeploy_key\n: A SSH private key with access to all non-public repositories\n  you specified in your repository configuration (i.e. all instances of\n  \nrepodeploy::repos\n occuring in your configuration). We strongly recommend\n  against adding this deploy key to your heat template. Current best practice\n  is to pass it as a parameter (with the \nhidden\n attribute enabled). \n\n\n\n\n\n\nDeclaration Example\n\n\n  bootstrap:\n      type: AS::autostrap::v1\n      properties:\n        deploy_key: { get_param: deploy_key }\n        config_repo: \nmy-config-url\n\n        config_branch: \n\n\n\n\nInstance Attachment Example\n\n\n  my_machine:\n    type: OS::Nova::Server\n      properties:\n        name: my_machine\n        user_data: { get_attr: [ bootstrap, script ] }\n        user_data_format: RAW\n\n\n\n\nNote the \"::v1\" trailing the resource declaration. Like all of Autostrap's\ncustom resources, this resource is versioned: whenever we introduce breaking\nAPI changes we increment the version number. This way you can generally rely on\na given version continuing to behave as as expected.\n\n\nRequired Metadata parameters for instances\n\n\nYou will need to pass at least the following heat parameters to instances\n(\nOS::Nova::Server\n resources) to be deployed using Autostrap:\n\n\n\n\ntopics\n - The configuration topics to deploy on the instance in question\n  (see \nAdding Configuration Topics from global-config\n).\n\n\n\n\nAdditionally, it is recommended to set the following metadata parameters:\n\n\n\n\n\n\nstack_name\n - Available to puppet through the fact \nopenstack_stack_name\n\n  (requires the puppet module openstackfacts)\n\n\n\n\n\n\nfloating_ip\n - Available to puppet through the fact \nopenstack_floating_ip\n\n  (requires the puppet module openstackfacts)\n\n\n\n\n\n\nIf you have followed the recommendations above, a machine's metadata property\nmight look as follows:\n\n\n      metadata:\n        stack_name: { get_param: 'OS::stack_name' }\n          topics: \nbase ssh puppet-masterless\n\n          stack_name: { get_param: 'OS::stack_name' }\n          floating_ip: { get_attr: [ my_port, floating_ip_address ] }\n          topics: \nbase ssh puppet-masterless\n\n\n\n\n\n\n\n\nStep 2: Adding Configuration Topics From global-config\n\n\nNow you will have to pick configuration \ntopics\n to deploy from\n\nglobal-config\n. Each topic consists of\na set of puppet classes required to deploy the service or other configuration\nit deploys, hiera configuration and a list of repositories containing the\npuppet modules it uses.\n\n\nAt a minimum, you will need the \npuppet-masterless\n topic. Additionally,\n\nbase\n (sensible configuration and useful packages) and \nssh\n (sensible sshd\nconfiguration and rollout of ssh authorized keys) are highly recommended.\n\n\nOnce you have picked topics, edit your heat template and add them to the\n\ntopics\n metadata entry of the instances they are to be deployed on. This\nmetadata entry is a simple space separated list. If we assume you picked all\ntopics recommended in the previous paragraph, a machine's meta data would contain\nthe following entry:\n\n\n      metadata:\n        topics: \nbase ssh puppet-masterless\n\n\n\n\n\nStep 3: Forking and Customizing project-config\n\n\nSince you probably want to add custom configuration of your own beyond that\nprovided by \nglobal-config\n, you will\nnow need to fork \nproject-config\n.  This fork is the\nrepository we referred to as \nmy-config\n in the\n\nPrerequisites\n section above.\n\n\nControlling access to \nmy-config\n\n\nmy-config\n must be reachable from the Internet, so your Openstack instances\ncan use it to retrieve your projects's configuration. It can be reachable\nthrough a public HTTPS URL, but we strongly recommend to make it accessible\nthrough SSH with public-key authentication. \n\n\nIf you do make \nmy-config\n non-public you will have to supply a\n\ndeploy_key\n property to your\n\nAs::autostrap\n resource. This property must contain a SSH private key that\ncan access \nmy-config\n.\n\n\nCustomizing \nmy-config\n\n\nNow you can modify \nmy-config\n to your heart's content. The changes and\nadditions will then be deployed on your heat stack's machines. You can put\nHiera configuration into the following subdirectories of \nmy-config\n:\n\n\n\n\n\n\npuppet/hieradata/config.d\n: This directory contains hiera configuration\n  relevant to all nodes/node types. It should contain all configuration that is\n  not confined to any specific node or node type. One example for such a\n  configuration value would be the list of SSH authorized keys, configured in\n  the \nssh::keys\n hash.  File and directory names in this directory are\n  free-form (every file with a .yaml extension will be included), but it is\n  recommended to organize configuration by topic name for easier navigation by\n  developers.\n\n\n\n\n\n\npuppet/hieradata/repos.d\n: This directory contains\n  \npuppet-repodeploy\n configuration, i.e. zero or more\n  instances of the \nrepodeploy::repos\n hash.  This hash specifies repositories\n  to be checked out by \npuppet-repodeploy\n. File and\n  directory names in this directory are free-form (every file with a .yaml\n  extension will be included), but it is recommended to organize configuration\n  by topic name for easier navigation by developers.\n\n\n\n\n\n\npuppet/hieradata/nodes.d\n: This directory contains node specific\n  configuration. It should only contain configuration that is relevant to\n  specific nodes. All file names in this directory must be the target node's\n  FQDN plus a '.yaml' extension, e.g. \npuppetmaster.local.yaml\n. All nodes\n  start out with a FQDN of 'hostname'.local.\n\n\n\n\n\n\npuppet/hieradata/nodetypes.d\n: This directory contains node type specific\n  configuration. A node's node type (such as \nappserver\n) is assigned by\n  setting the \nnodetype\n metadata entry. All file names in this directory must\n  be the target node type's name as given in the \nnodetype\n metadata entry,\n  plus a '.yaml' extension, e.g. \nappserver.yaml\n.\n\n\n\n\n\n\nAll classes to be included in puppet's catalog should be declared either on a\nper-node or a per-nodetype basis, unless they are part of a topic from the\n\ntopics\n metadata entry already, of course. This means adding a \nclasses\n array\nto a file in \npuppet/hieradata/nodes.d\n and/or \npuppet/hieradata/nodetypes.d\n.\n\n\nRefer to the  example project-config repository's \nREADME.md\nfile\n file for more detailed information on these\ndirectories and their contents.\n\n\nLast but not least, you can add last-minute commands to be run at the end of the\nbootstrapping process to \nbootstrap.d/additional\n. This is the place for\neverything that cannot be handled using puppet. This script will run on all\nnodes using \nmy-config\n as its project configuration repository.\n\n\nConfiguring \nmy-config\n in your Heat template\n\n\nAs a final step, you will need to make the Heat stack you are creating aware of\nyour \nmy-config\n repository. To this end, simply pass \nmy-config-url\n as\n\nconfig_repo\n property to\nyour \nAS::autostrap\n resource.\n\n\nStep 5: Deploying From Your Heat Template\n\n\nOnce configuration is finished and pushed to the \nmy-config\n repository and\nyour heat template contains the neccessary elements you can deploy a heat stack\nroughly as follows:\n\n\nheat stack-create -f mycloud.yaml \\\n                  -P key_name=\nnova key name\n \\\n                  -P deploy_key=\n$(cat ~/.ssh/deploy_key)\n \\\n                  my-masterless-stack\n\n\n\n\nSubstitute the key name you specified when uploading your SSH key to nova for\n\nnova key name\n. You may also have to supply a \npublic_net_id\n parameter.\n\n\nOther parameters supplied to \nheat stack-create\n may vary. This example assumes a\nlargely unmodified copy of the \nnginx-masterless.yaml\n example template with\njust the \nconfig_repo\n parameter's default changed to \nmy-config-url\n.", 
            "title": "Deployment Workflow"
        }, 
        {
            "location": "/workflow/#prerequisites", 
            "text": "Following the deployment instructions described in this section requires the following:   A user account on an Openstack cloud  The Openstack  command-line clients  git  A remotely accessible (e.g. through SSH or HTTPS) git repository for storing\n  project specific configuration. This repository should start out as a fork of\n  Autostrap's  sample project-config repository . Throughout this section we will\n  refer to this repository with the placeholder  my-config  and to its url with\n  the placeholder  my-config-url .  An editor with syntax highlighting for  YAML  (optional, but recommended)  The syseleven.cloudutils package for smoother handling of heat stacks\n  (optional, but recommended). A simple  pip install syseleven.cloudutils \n  should take care of this.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/workflow/#puppet-masteragent-based-configuration", 
            "text": "For larger setups a Puppet master can be automatically deployed, with all nodes\n(including the Puppet master itself) running Puppet agents. This approach is\nrecommended for any setup beyond two nodes. This approach consists of a\nmasterless first stage that sets up the Puppet master and its agent, with\nconfiguration being provided through the Puppet master from there on out.", 
            "title": "Puppet Master/Agent Based Configuration"
        }, 
        {
            "location": "/workflow/#step-1-creating-a-heat-template", 
            "text": "First of all you will need to describe your projects requirements in terms of a\nHeat template. As a starting point, the Heat project provides some  guidelines \non writing heat templates.  Autostrap requires various meta data parameters and its own user-data script,\nso we recommend you modify one of our example templates in the  heat-templates \ndirectory of  project-config  to fit your project's\nrequirements.", 
            "title": "Step 1: Creating a Heat Template"
        }, 
        {
            "location": "/workflow/#adding-a-asautostrap-resource", 
            "text": "The custom Heat resource  AS::autostrap  generates a user-data script that\nwill kick off the autostrap deployment process. This user-data script is then\npassed to your instances ( OS::Nova::Server  resources) as user-data property.  Properties  The following properties of  AS::autostrap  are most likely to be relevant\nto deploying a new project (refer to the  AS::autostrap  documentation for\nthe rest):    config_repo : The URL of your project specific configuration repository, i.e.\n   my-config-url .    config_branch : An optional branch/revision of your configuration repository\n  to check out. This is mainly useful for development and best sourced from a\n  Heat parameter that defaults to 'master' (thus allowing you to specify\n  experimental/development branches at run-time, while defaulting to a\n  known-good stable branch otherwise).'    deploy_key : A SSH private key with access to all non-public repositories\n  you specified in your repository configuration (i.e. all instances of\n   repodeploy::repos  occuring in your configuration). We strongly recommend\n  against adding this deploy key to your heat template. Current best practice\n  is to pass it as a parameter (with the  hidden  attribute enabled).     Declaration Example    bootstrap:\n      type: AS::autostrap::v1\n      properties:\n        deploy_key: { get_param: deploy_key }\n        config_repo:  my-config-url \n        config_branch:   Instance Attachment Example    my_machine:\n    type: OS::Nova::Server\n      properties:\n        name: my_machine\n        user_data: { get_attr: [ bootstrap, script ] }\n        user_data_format: RAW  Note the \"::v1\" trailing the resource declaration. Like all of Autostrap's\ncustom resources, this resource is versioned: whenever we introduce breaking\nAPI changes we increment the version number. This way you can generally rely on\na given version continuing to behave as as expected.", 
            "title": "Adding a AS::autostrap resource"
        }, 
        {
            "location": "/workflow/#required-metadata-parameters-for-instances", 
            "text": "You will need to pass at least the following heat parameters to instances\n( OS::Nova::Server  resources) to be deployed using Autostrap:   topics  - The configuration topics to deploy on the instance in question\n  (see  Adding Topics to the Puppet Master ).   Additionally, it is recommended to set the following metadata parameters:    stack_name  - Available to puppet through the fact  openstack_stack_name \n  (requires the puppet module openstackfacts)    floating_ip  - Available to puppet through the fact  openstack_floating_ip \n  (requires the puppet module openstackfacts)    If you have followed the recommendations above, a regular machine's metadata property\nmight look as follows:        metadata:\n        stack_name: { get_param: 'OS::stack_name' }\n          topics:  base ssh puppet-master-agent \n          stack_name: { get_param: 'OS::stack_name' }\n          floating_ip: { get_attr: [ my_port, floating_ip_address ] }\n          topics:  base ssh puppet-master-agent   The puppetmaster's metadata property might then look like this:        metadata:\n        stack_name: { get_param: 'OS::stack_name' }\n          topics:  base ssh puppet-master-agent \n          stack_name: { get_param: 'OS::stack_name' }\n          floating_ip: { get_attr: [ my_port, floating_ip_address ] }\n          topics:  base ssh puppet-master-agent", 
            "title": "Required Metadata parameters for instances"
        }, 
        {
            "location": "/workflow/#step-2-adding-configuration-topics-from-global-config", 
            "text": "Now you will have to pick configuration  topics  to deploy from global-config . Each topic consists of\na set of puppet classes required to deploy the service or other configuration\nit deploys, hiera configuration and a list of repositories containing the\npuppet modules it uses.  At a minimum, you will need the  puppet-master  topic on the designated puppet\nmaster and the  puppet-agent  topic on all nodes (including the puppet master).\nAdditionally,  base  (sensible configuration and useful packages) and  ssh \n(sensible sshd configuration and rollout of ssh public keys) are highly\nrecommended.  Once you have picked topics, edit your heat template and add them to the topics  metadata entry of the instances they are to be deployed on. This\nmetadata entry is a simple space separated list. If we assume you picked all\ntopics recommended in the previous paragraph, a machine's meta data would contain\nthe following entry:        metadata:\n        topics:  base ssh puppet-master-agent", 
            "title": "Step 2: Adding Configuration Topics From global-config "
        }, 
        {
            "location": "/workflow/#step-3-adding-topics-to-the-puppet-master", 
            "text": "The  configuration topics  you picked in the previous section\nwill be deployed in a masterless fashion upon node initialization. In addition\nto these you can and should now pick topics from global-config  to be available through\nthe puppet master. To this end, simply add their topic names (each on a single\nline) to the  puppet/topics  file in the  my-config  repository. These\ntopics'  config.d  and  repos.d  subdirectories will be included in the puppet\nmasters Hiera hierarchy, making the topics' configuration available and causing\nits component puppet modules to be checked out on the puppet master. Declaring\nthese topics' component classes for individual nodes or node types will be up to you\n(see the next section).", 
            "title": "Step 3: Adding Topics to the Puppet Master "
        }, 
        {
            "location": "/workflow/#step-4-forking-and-customizing-project-config", 
            "text": "Since you probably want to add custom configuration of your own beyond that\nprovided by  global-config , you will\nnow need to fork  project-config ).\nThis fork is the repository we referred to as  my-config  in the Prerequisites  section above.  Controlling access to  my-config  my-config  must be reachable from the Internet, so your Openstack instances\ncan use it to retrieve your projects's configuration. It can be reachable\nthrough a public HTTPS URL, but we strongly recommend to make it accessible\nthrough SSH with public-key authentication.   If you do make  my-config  non-public you will have to supply a deploy_key  property to your AS::autostrap  resource. This property must contain a SSH private key that\ncan access  my-config .  Customizing  my-config  Now you can modify  my-config  to your heart's content. The changes and\nadditions will then be deployed on your heat stack's machines. You can put\nHiera configuration into the following subdirectories of  my-config :    puppet/hieradata/config.d : This directory contains hiera configuration\n  relevant to all nodes/node types. It should contain all configuration that is\n  not confined to any specific node or node type. One example for such a\n  configuration value would be the list of SSH authorized keys, configured\n  in the  ssh::keys  hash. File and directory names in this directory are\n  free-form (every file with a .yaml extension will be included), but it is\n  recommended to organize configuration by topic name for easier navigation by\n  developers.    puppet/hieradata/repos.d : This directory contains  puppet-repodeploy \n  configuration, i.e. zero or more instances of the  repodeploy::repos  hash.\n  This hash specifies repositories to be checked out by  puppet-repodeploy . File\n  and directory names in this directory are free-form (every file with a .yaml\n  extension will be included), but it is recommended to organize configuration\n  by topic name for easier navigation by developers.    puppet/hieradata/nodes.d : This directory contains node specific\n  configuration. It should only contain configuration that is relevant to\n  specific nodes. All file names in this directory must be the target node's\n  FQDN plus a '.yaml' extension, e.g.  puppetmaster.local.yaml . All nodes\n  start out with a FQDN of 'hostname'.local. The  classes  array holding the\n  classes to be deployed on a given node should be defined here.    puppet/hieradata/nodetypes.d : This directory contains node type specific\n  configuration. A node's node type (such as  appserver ) is assigned by\n  setting the  nodetype  metadata entry. All file names in this directory must\n  be the target node type's name as given in the  nodetype  metadata entry,\n  plus a '.yaml' extension, e.g.  appserver.yaml . The  classes  array holding\n  the classes to be deployed on a given node type should be defined here.    Refer to the  example project-config repository's  README.md file \nfile for more detailed information on these directories and their contents.  Configuring classes to be deployed on nodes and node types   All classes to be included in the puppet master's catalog should be declared\neither on a per-node or a per-nodetype basis, i.e. in puppet/hieradata/nodes.d  or  puppet/hieradata/nodetypes.d , respectively. If\nyou wish to deploy one or more of the ready-made topics from  global-config ,\nfor a given node or node type you will need to do two things:    Ensure the topics' configuration and component puppet modules are available\n   on the puppet master (see  Adding Topics to the Puppet Master ).    Add the topics' classes to your nodes' and/or nodetypes' classes arrays.    For the latter step you can use the  merge_classes  script from the autostrap-utils  repository.\nThis script will gather multiple topics' classes arrays from  global-config \nand merge them into a classes array ready for inclusion in a configuration file\nin  nodes.d  or  nodetypes.d . The following example generates a classes array\ncontaining the  nginx-server , and  puppet-agent  topics:  git clone https://github.com/autostrap/global-config.git /tmp/global-config\nmerge_classes --classes-dir /tmp/global-config/puppet/hieradata/classes.d \\\n              nginx-server puppet-agent  This would yield the following classes array, which also happens to be a valid\nnode/node type configuration:  classes:\n  -  nginx \n  -  autopuppet::role::agent   To include it in an existing node configuration you would have to remove the ---  in the first line, since leaving it in place would indicate the begin of\na new YAML document.", 
            "title": "Step 4: Forking and Customizing project-config"
        }, 
        {
            "location": "/workflow/#step-5-deploying-from-your-heat-template", 
            "text": "Once configuration is finished and pushed to the  my-config  repository and\nyour heat template contains the neccessary elements you can deploy a heat stack\nroughly as follows  heat stack-create -f mycloud.yaml \\\n                  -P key_name= nova key name  \\\n                  -P deploy_key= $(cat ~/.ssh/deploy_key)  \\\n                  my-master-agent-stack  Substitute the key name you specified when uploading your SSH key to nova for nova key name .  You may also have to supply a  public_net_id  parameter.  Other parameters supplied to  heat stack-create  may vary. This example assumes a\nlargely unmodified copy of the  sensu-master-agent.yaml  example template with\njust the  config_repo  parameter's default changed to  my-config-url .", 
            "title": "Step 5: Deploying From Your Heat Template"
        }, 
        {
            "location": "/workflow/#masterless-puppet-configuration", 
            "text": "This approach is meant for small setups that typically consist of only one or\ntwo servers. In this case a Puppet master is not really needed. Consequently,\nall configuration and Puppet modules relevant to the node in question will be\nlocally available on any node. A cronjob will run puppet locally on a regular\nbasis. The diagram below gives an overview of the steps involved in a\nmasterless puppet setup:", 
            "title": "Masterless Puppet Configuration"
        }, 
        {
            "location": "/workflow/#step-1-creating-a-heat-template_1", 
            "text": "First of all you will need to describe your projects requirements in terms of a\nHeat template. As a starting point, the Heat project provides some  guidelines \non writing heat templates.  Autostrap requires various meta data parameters and an Autostrap provided\nuser-data script, so we recommend you modify one of our example templates in\nthe heat-templates directory of  project-config \nto fit your project's requirements.", 
            "title": "Step 1: Creating a Heat Template"
        }, 
        {
            "location": "/workflow/#adding-a-asautostrap-resource_1", 
            "text": "The custom Heat resource  AS::autostrap  generates a user-data script that\nwill kick off the autostrap deployment process. This user-data script is then\npassed to your instances ( OS::Nova::Server  resources) as user-data property.  Properties  The following properties of  AS::autostrap  are most likely to be relevant\nto deploying a new project (refer to the  AS::autostrap  documentation for\nthe rest):    config_repo : The URL of your project specific configuration repository, i.e.\n   my-config-url .     config_branch : An optional branch/revision of your configuration repository\n  to check out. This is mainly useful for development and best sourced from a\n  Heat parameter that defaults to 'master' (thus allowing you to specify\n  experimental/development branches at run-time, while defaulting to a\n  known-good stable branch otherwise).'    deploy_key : A SSH private key with access to all non-public repositories\n  you specified in your repository configuration (i.e. all instances of\n   repodeploy::repos  occuring in your configuration). We strongly recommend\n  against adding this deploy key to your heat template. Current best practice\n  is to pass it as a parameter (with the  hidden  attribute enabled).     Declaration Example    bootstrap:\n      type: AS::autostrap::v1\n      properties:\n        deploy_key: { get_param: deploy_key }\n        config_repo:  my-config-url \n        config_branch:   Instance Attachment Example    my_machine:\n    type: OS::Nova::Server\n      properties:\n        name: my_machine\n        user_data: { get_attr: [ bootstrap, script ] }\n        user_data_format: RAW  Note the \"::v1\" trailing the resource declaration. Like all of Autostrap's\ncustom resources, this resource is versioned: whenever we introduce breaking\nAPI changes we increment the version number. This way you can generally rely on\na given version continuing to behave as as expected.", 
            "title": "Adding a AS::autostrap resource"
        }, 
        {
            "location": "/workflow/#required-metadata-parameters-for-instances_1", 
            "text": "You will need to pass at least the following heat parameters to instances\n( OS::Nova::Server  resources) to be deployed using Autostrap:   topics  - The configuration topics to deploy on the instance in question\n  (see  Adding Configuration Topics from global-config ).   Additionally, it is recommended to set the following metadata parameters:    stack_name  - Available to puppet through the fact  openstack_stack_name \n  (requires the puppet module openstackfacts)    floating_ip  - Available to puppet through the fact  openstack_floating_ip \n  (requires the puppet module openstackfacts)    If you have followed the recommendations above, a machine's metadata property\nmight look as follows:        metadata:\n        stack_name: { get_param: 'OS::stack_name' }\n          topics:  base ssh puppet-masterless \n          stack_name: { get_param: 'OS::stack_name' }\n          floating_ip: { get_attr: [ my_port, floating_ip_address ] }\n          topics:  base ssh puppet-masterless", 
            "title": "Required Metadata parameters for instances"
        }, 
        {
            "location": "/workflow/#step-2-adding-configuration-topics-from-global-config_1", 
            "text": "Now you will have to pick configuration  topics  to deploy from global-config . Each topic consists of\na set of puppet classes required to deploy the service or other configuration\nit deploys, hiera configuration and a list of repositories containing the\npuppet modules it uses.  At a minimum, you will need the  puppet-masterless  topic. Additionally, base  (sensible configuration and useful packages) and  ssh  (sensible sshd\nconfiguration and rollout of ssh authorized keys) are highly recommended.  Once you have picked topics, edit your heat template and add them to the topics  metadata entry of the instances they are to be deployed on. This\nmetadata entry is a simple space separated list. If we assume you picked all\ntopics recommended in the previous paragraph, a machine's meta data would contain\nthe following entry:        metadata:\n        topics:  base ssh puppet-masterless", 
            "title": "Step 2: Adding Configuration Topics From global-config"
        }, 
        {
            "location": "/workflow/#step-3-forking-and-customizing-project-config", 
            "text": "Since you probably want to add custom configuration of your own beyond that\nprovided by  global-config , you will\nnow need to fork  project-config .  This fork is the\nrepository we referred to as  my-config  in the Prerequisites  section above.  Controlling access to  my-config  my-config  must be reachable from the Internet, so your Openstack instances\ncan use it to retrieve your projects's configuration. It can be reachable\nthrough a public HTTPS URL, but we strongly recommend to make it accessible\nthrough SSH with public-key authentication.   If you do make  my-config  non-public you will have to supply a deploy_key  property to your As::autostrap  resource. This property must contain a SSH private key that\ncan access  my-config .  Customizing  my-config  Now you can modify  my-config  to your heart's content. The changes and\nadditions will then be deployed on your heat stack's machines. You can put\nHiera configuration into the following subdirectories of  my-config :    puppet/hieradata/config.d : This directory contains hiera configuration\n  relevant to all nodes/node types. It should contain all configuration that is\n  not confined to any specific node or node type. One example for such a\n  configuration value would be the list of SSH authorized keys, configured in\n  the  ssh::keys  hash.  File and directory names in this directory are\n  free-form (every file with a .yaml extension will be included), but it is\n  recommended to organize configuration by topic name for easier navigation by\n  developers.    puppet/hieradata/repos.d : This directory contains\n   puppet-repodeploy  configuration, i.e. zero or more\n  instances of the  repodeploy::repos  hash.  This hash specifies repositories\n  to be checked out by  puppet-repodeploy . File and\n  directory names in this directory are free-form (every file with a .yaml\n  extension will be included), but it is recommended to organize configuration\n  by topic name for easier navigation by developers.    puppet/hieradata/nodes.d : This directory contains node specific\n  configuration. It should only contain configuration that is relevant to\n  specific nodes. All file names in this directory must be the target node's\n  FQDN plus a '.yaml' extension, e.g.  puppetmaster.local.yaml . All nodes\n  start out with a FQDN of 'hostname'.local.    puppet/hieradata/nodetypes.d : This directory contains node type specific\n  configuration. A node's node type (such as  appserver ) is assigned by\n  setting the  nodetype  metadata entry. All file names in this directory must\n  be the target node type's name as given in the  nodetype  metadata entry,\n  plus a '.yaml' extension, e.g.  appserver.yaml .    All classes to be included in puppet's catalog should be declared either on a\nper-node or a per-nodetype basis, unless they are part of a topic from the topics  metadata entry already, of course. This means adding a  classes  array\nto a file in  puppet/hieradata/nodes.d  and/or  puppet/hieradata/nodetypes.d .  Refer to the  example project-config repository's  README.md\nfile  file for more detailed information on these\ndirectories and their contents.  Last but not least, you can add last-minute commands to be run at the end of the\nbootstrapping process to  bootstrap.d/additional . This is the place for\neverything that cannot be handled using puppet. This script will run on all\nnodes using  my-config  as its project configuration repository.  Configuring  my-config  in your Heat template  As a final step, you will need to make the Heat stack you are creating aware of\nyour  my-config  repository. To this end, simply pass  my-config-url  as config_repo  property to\nyour  AS::autostrap  resource.", 
            "title": "Step 3: Forking and Customizing project-config"
        }, 
        {
            "location": "/workflow/#step-5-deploying-from-your-heat-template_1", 
            "text": "Once configuration is finished and pushed to the  my-config  repository and\nyour heat template contains the neccessary elements you can deploy a heat stack\nroughly as follows:  heat stack-create -f mycloud.yaml \\\n                  -P key_name= nova key name  \\\n                  -P deploy_key= $(cat ~/.ssh/deploy_key)  \\\n                  my-masterless-stack  Substitute the key name you specified when uploading your SSH key to nova for nova key name . You may also have to supply a  public_net_id  parameter.  Other parameters supplied to  heat stack-create  may vary. This example assumes a\nlargely unmodified copy of the  nginx-masterless.yaml  example template with\njust the  config_repo  parameter's default changed to  my-config-url .", 
            "title": "Step 5: Deploying From Your Heat Template"
        }, 
        {
            "location": "/howto/", 
            "text": "How do I...\n\n\nThis section contains short HOWTO guides for various common tasks.\n\n\n\n\n...run autostrap.standalone?\n\n\nFirst of all you need a blank machine which fullfills the following\nrequirements:\n\n\n\n\n\n\nUbuntu 14.04\n\n\n\n\n\n\nInternet Access\n\n\n\n\n\n\nBash, Python, Git\n\n\n\n\n\n\nA deploy key for the private repositories you might use during bootstrapping\n  in \n/root/deploy\n (optional, but usually neccessary).\n\n\n\n\n\n\nWe recommend using a throwaway vagrant instance for this purpose.\n\n\nOn your machine, run the following commands:\n\n\ngit clone https://github.com/autostrap/bootstrap-scripts.git \\\n         /tmp/bootstrap-scripts\nunset SSH_AUTH_SOCK     # This ensures the deploy key is used \n                        # (as opposed to a key an SSH agent might\n                        # be forwarding)\ncd /tmp/bootstrap-scripts/stage0\ndeploy_key=\n$(cat /root/deploy)\n ./autostrap.standalone  \\\n           -m topics=\nbase puppet-masterless\n \\\n           -m nodetype=docbox\n\n\n\n\nThis example will give you a nginx web server managed through masterless\npuppet, hosting this documentation. You can vary topics and other metadata\nparameters and/or environment variables (the Heat properties recognized by\n\nAS::autostrap\n are retrieved from identically named environment variables by\n\nautostrap.standalone\n) as needed to create other setups.\n\n\nNote: \nautostrap.standalone\n will not output anything on the console. To\nmonitor progress tail the following files:\n\n\n\n\n\n\n/var/log/autostrap/stage0.log\n\n\n\n\n\n\n/var/log/initialize_instance.log (only appears once initialize_instance has been launched)\n\n\n\n\n\n\n\n\n...deploy SSH public keys to my Instances?\n\n\nFirst of all, you need to enable the \nssh topic\n on the machines\nyou wish to deploy authorized keys on.\n\n\nAuthorized SSH keys can be then be stored anywhere in your Hiera configuration\n(i.e. in your \nproject-config\n or an\n\nadditional_config\n repository). Variables containing SSH\nkeys must be hashes and have the following format:\n\n\nssh::keys:\n  'mykeyname':\n    type: ssh-rsa | ssh-dss\n    user: \nuser\n\n    key: \nraw key\n\n    ensure: present | absent\n\n\n\n\nThis hash is keyed by free-form SSH key names.  Entries in this hash in turn\ncontain a hash with the following keys/values:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntype (required)\n\n\nThe key's type, e.g. \nssh-dss\n or \nssh-rsa\n.\n\n\n\n\n\n\nuser (required)\n\n\nThe user whose \n~/.ssh/authorized_keys\n this key should be added to\n\n\n\n\n\n\nkey (required)\n\n\nThe raw public key, without the type and comment fields, (e.g. what you'd get from an \nawk '{print $2}' ~/.ssh/*.pub\n).\n\n\n\n\n\n\nensure (optional)\n\n\nWhether to ensure the key being present or absent (defaults to present).\n\n\n\n\n\n\n\n\nThere may be multiple variables containing such hashes. You can control which\nof these are merged to form the final hash of authorized keys in one of two\nways:\n\n\nBy default, Autostrap uses the hash \nssh::keys\n if the \nssh\n\n\ntopic\n is enabled for a machine. Typically you would create\nthis as a default hash in global-config and add to it in project-config. To\nprevent such a hash in global-config (e.g. if you create a project-config for a\nsetup restricted to a smaller circle of keys than the ones found in your\nglobal-config repository) from being used you can use one of the following\nmethods:\n\n\n\n\n\n\nYou can set the Hiera variable \nssh::key_sources\n. This is an array\n   containing the Hiera variables to retrieve authorized keys from.\n\n\n\n\n\n\nYou can supply the same thing as a space-delimited list of hiera variable\n   names in the metadata parameter \nsshkeys\n. This is ok for testing, but not\n   recommended in production. If the Hiera variable \nssh::key_sources\n is set,\n   it will take precedence over this metadata parameter, i.e. the metadata\n   parameter will be ignored.\n\n\n\n\n\n\nIf you do not set the list of SSH key sources explicitely, it will default to\nthe following variable:\n\n\n\n\nssh::keys\n\n\n\n\nAdditionally, \nssh::authorized_keys::authorized_keys\n will be appended to\n\nssh::key_sources\n if it is defined anywhere in your Hiera configuration. This\nensures legacy setups that still store their SSH keys in\n\nssh::authorized_keys::authorized_keys\n will continue to function.\n\n\nExamples\n\n\nIn this section you will find examples for configuring a custom list of Hiera\nvariables to retrieve SSH authorized keys from, for both approaches outlined\nabove. While you can use either of these approaches, we strongly recommend\nusing the \nssh::key_sources\n Hiera variable (it will also take precedence over\nthe metadata approach if both types of configuration are used).\n\n\nConfiguring the SSH key hash names through Hiera\n\n\nTo retrieve your SSH key hashes from the variables \nssh::keys::mykeys\n and\n\nssh::keys::myotherkeys\n you would add the following to your Hiera\nconfiguration:\n\n\nssh::key_sources:\n - ssh::keys::mykeys\n - ssh::keys::myotherkeys\n\n\n\n\nConfiguring the SSH key hash names through the \nsshkeys\n metadata entry\n\n\nTo retrieve your SSH key hashes from the variables \nssh::keys::mykeys\n and\n\nssh::keys::myotherkeys\n you would add the following entry to the \nmetadata\n\nkey of your \nOS::Nova::Server\n resources:\n\n\nmynode:\n  type: OS::Nova::Server\n  properties:\n    [...]\n    metadata:\n      sshkeys: 'ssh::keys::mykeys ssh::keys::myotherkeys'", 
            "title": "How do I..."
        }, 
        {
            "location": "/howto/#how-do-i", 
            "text": "This section contains short HOWTO guides for various common tasks.", 
            "title": "How do I..."
        }, 
        {
            "location": "/howto/#run-autostrapstandalone", 
            "text": "First of all you need a blank machine which fullfills the following\nrequirements:    Ubuntu 14.04    Internet Access    Bash, Python, Git    A deploy key for the private repositories you might use during bootstrapping\n  in  /root/deploy  (optional, but usually neccessary).    We recommend using a throwaway vagrant instance for this purpose.  On your machine, run the following commands:  git clone https://github.com/autostrap/bootstrap-scripts.git \\\n         /tmp/bootstrap-scripts\nunset SSH_AUTH_SOCK     # This ensures the deploy key is used \n                        # (as opposed to a key an SSH agent might\n                        # be forwarding)\ncd /tmp/bootstrap-scripts/stage0\ndeploy_key= $(cat /root/deploy)  ./autostrap.standalone  \\\n           -m topics= base puppet-masterless  \\\n           -m nodetype=docbox  This example will give you a nginx web server managed through masterless\npuppet, hosting this documentation. You can vary topics and other metadata\nparameters and/or environment variables (the Heat properties recognized by AS::autostrap  are retrieved from identically named environment variables by autostrap.standalone ) as needed to create other setups.  Note:  autostrap.standalone  will not output anything on the console. To\nmonitor progress tail the following files:    /var/log/autostrap/stage0.log    /var/log/initialize_instance.log (only appears once initialize_instance has been launched)", 
            "title": "...run autostrap.standalone?"
        }, 
        {
            "location": "/howto/#deploy-ssh-public-keys-to-my-instances", 
            "text": "First of all, you need to enable the  ssh topic  on the machines\nyou wish to deploy authorized keys on.  Authorized SSH keys can be then be stored anywhere in your Hiera configuration\n(i.e. in your  project-config  or an additional_config  repository). Variables containing SSH\nkeys must be hashes and have the following format:  ssh::keys:\n  'mykeyname':\n    type: ssh-rsa | ssh-dss\n    user:  user \n    key:  raw key \n    ensure: present | absent  This hash is keyed by free-form SSH key names.  Entries in this hash in turn\ncontain a hash with the following keys/values:           type (required)  The key's type, e.g.  ssh-dss  or  ssh-rsa .    user (required)  The user whose  ~/.ssh/authorized_keys  this key should be added to    key (required)  The raw public key, without the type and comment fields, (e.g. what you'd get from an  awk '{print $2}' ~/.ssh/*.pub ).    ensure (optional)  Whether to ensure the key being present or absent (defaults to present).     There may be multiple variables containing such hashes. You can control which\nof these are merged to form the final hash of authorized keys in one of two\nways:  By default, Autostrap uses the hash  ssh::keys  if the  ssh  topic  is enabled for a machine. Typically you would create\nthis as a default hash in global-config and add to it in project-config. To\nprevent such a hash in global-config (e.g. if you create a project-config for a\nsetup restricted to a smaller circle of keys than the ones found in your\nglobal-config repository) from being used you can use one of the following\nmethods:    You can set the Hiera variable  ssh::key_sources . This is an array\n   containing the Hiera variables to retrieve authorized keys from.    You can supply the same thing as a space-delimited list of hiera variable\n   names in the metadata parameter  sshkeys . This is ok for testing, but not\n   recommended in production. If the Hiera variable  ssh::key_sources  is set,\n   it will take precedence over this metadata parameter, i.e. the metadata\n   parameter will be ignored.    If you do not set the list of SSH key sources explicitely, it will default to\nthe following variable:   ssh::keys   Additionally,  ssh::authorized_keys::authorized_keys  will be appended to ssh::key_sources  if it is defined anywhere in your Hiera configuration. This\nensures legacy setups that still store their SSH keys in ssh::authorized_keys::authorized_keys  will continue to function.", 
            "title": "...deploy SSH public keys to my Instances?"
        }, 
        {
            "location": "/howto/#examples", 
            "text": "In this section you will find examples for configuring a custom list of Hiera\nvariables to retrieve SSH authorized keys from, for both approaches outlined\nabove. While you can use either of these approaches, we strongly recommend\nusing the  ssh::key_sources  Hiera variable (it will also take precedence over\nthe metadata approach if both types of configuration are used).  Configuring the SSH key hash names through Hiera  To retrieve your SSH key hashes from the variables  ssh::keys::mykeys  and ssh::keys::myotherkeys  you would add the following to your Hiera\nconfiguration:  ssh::key_sources:\n - ssh::keys::mykeys\n - ssh::keys::myotherkeys  Configuring the SSH key hash names through the  sshkeys  metadata entry  To retrieve your SSH key hashes from the variables  ssh::keys::mykeys  and ssh::keys::myotherkeys  you would add the following entry to the  metadata \nkey of your  OS::Nova::Server  resources:  mynode:\n  type: OS::Nova::Server\n  properties:\n    [...]\n    metadata:\n      sshkeys: 'ssh::keys::mykeys ssh::keys::myotherkeys'", 
            "title": "Examples"
        }, 
        {
            "location": "/files/", 
            "text": "Repository Checkouts\n\n\nAutostrap repositories\n\n\n/opt/scripts/autostrap/\n\n\n/opt/config/additional/\n\n\n/opt/config/global/\n\n\n/opt/config/project/\n\n\n\n\n\n\nPuppet modules\n\n\n\n\n\n\nBootstrapping scripts\n\n\nLog Files\n\n\n/var/log/autostrap/stage0.log\n\n\n/var/log/script_user_data.log\n\n\n/var/log/initialize_instance.log\n\n\n\n\n\n\n\n\n\n\nThis section describes important files and directories you will find on a\nmachine set up by Autostrap. While the machine is still bootstrapping, some of\nthem will not be present, yet. If anything is missing, check\n\n/var/log/initialize_instance.log\n first: only if it contains the line\n\n\nfinished /opt/scripts/autostrap/initialize_instance\n\n\n\n\nbootstrapping is finished. If bootstrapping is finished but you are missing\nsomething nonetheless, the problem may among other things be a bad or missing\ndeploy key, or incorrect repository URLs. Check the rest of\n\n/var/log/initialize_instance.log\n (and the other logfiles mentioned below) to\ninvestigate.\n\n\nRepository Checkouts\n\n\nYou will find checkouts of the \nGit\n repositories that make up\nAutostrap in the following locations:\n\n\nAutostrap repositories\n\n\n/opt/scripts/autostrap/\n\n\nThis directory contains a checkout of the\n\nbootstrap-scripts\n repository. This directory contains\nthe most of the code running during bootstrapping. An alternative URL and\nrevision (e.g. for testing a topic branch) can be specified through the\n\nscripts_repo\n and \nscripts_branch\n parameters.\n\n\n/opt/config/additional/\n\n\nThis directory contains working copies of the repositories specified through\nthe \nadditional_config\n parameter (if any).\n\n\n/opt/config/global/\n\n\nThis directory contains a checkout of the \nglobal-config\n\nrepository. This repository's URL and revision are specified through the\n\nglobal_config_repo\n and \nglobal_config_branch\n parameters. By default\n\nAutostrap's sample global-config\n is used.\n\n\n/opt/config/project/\n\n\nThis directory contains a checkout of the \nproject-config\n\nrepository you specified through the \nconfig_repo\n and \nconfig_branch\n\nparameters.\n\n\nPuppet modules\n\n\nAll puppet modules included in Autostrap's \npuppet-repodeploy\n configuration\nare cloned to \n/opt/puppet-modules\n. We suggest you follow this convention for\nyour own modules as well, since this directory is in Puppet's module search\npath on Autostrap configured machines.\n\n\nBootstrapping scripts\n\n\nThe directory \n/opt/scripts/stages\n holds symlinks to all bootstrapping\nscripts, both from \nbootstrap-scripts\n and\n\nproject-config\n. It is the authoritative source for\nbootstrapping scripts on this machine, i.e. they are run from this directory.\n\n\nLog Files\n\n\n/var/log/autostrap/stage0.log\n\n\nIf you are using \nautostrap.standalone\n to\nstart the bootstrapping process, the first bootstrapping stage's output will go\nto this file. Once it launches \ninitialize_instance\n, logging will switch to\nthe second stage log file, \n/var/log/initialize_instance.log\n (see below).\n\n\n/var/log/script_user_data.log\n\n\nIf you are using the \nAS::autostrap\n Heat resource to start\nthe bootstrapping process, the first bootstrapping stage's output will go to\nthis file. Once the user-data script launches \ninitialize_instance\n, logging\nwill switch to the second stage log file \n/var/log/initialize_instance.log\n\n(see below).\n\n\n/var/log/initialize_instance.log\n\n\nThis file contains all logging output from the \nsecond bootstrapping\nstage\n. This is your most useful tool in\ninvestigating what went wrong if a machine fails to bootstrap.", 
            "title": "Files and Directories"
        }, 
        {
            "location": "/files/#repository-checkouts", 
            "text": "You will find checkouts of the  Git  repositories that make up\nAutostrap in the following locations:", 
            "title": "Repository Checkouts"
        }, 
        {
            "location": "/files/#autostrap-repositories", 
            "text": "/opt/scripts/autostrap/  This directory contains a checkout of the bootstrap-scripts  repository. This directory contains\nthe most of the code running during bootstrapping. An alternative URL and\nrevision (e.g. for testing a topic branch) can be specified through the scripts_repo  and  scripts_branch  parameters.  /opt/config/additional/  This directory contains working copies of the repositories specified through\nthe  additional_config  parameter (if any).  /opt/config/global/  This directory contains a checkout of the  global-config \nrepository. This repository's URL and revision are specified through the global_config_repo  and  global_config_branch  parameters. By default Autostrap's sample global-config  is used.  /opt/config/project/  This directory contains a checkout of the  project-config \nrepository you specified through the  config_repo  and  config_branch \nparameters.", 
            "title": "Autostrap repositories"
        }, 
        {
            "location": "/files/#puppet-modules", 
            "text": "All puppet modules included in Autostrap's  puppet-repodeploy  configuration\nare cloned to  /opt/puppet-modules . We suggest you follow this convention for\nyour own modules as well, since this directory is in Puppet's module search\npath on Autostrap configured machines.", 
            "title": "Puppet modules"
        }, 
        {
            "location": "/files/#bootstrapping-scripts", 
            "text": "The directory  /opt/scripts/stages  holds symlinks to all bootstrapping\nscripts, both from  bootstrap-scripts  and project-config . It is the authoritative source for\nbootstrapping scripts on this machine, i.e. they are run from this directory.", 
            "title": "Bootstrapping scripts"
        }, 
        {
            "location": "/files/#log-files", 
            "text": "", 
            "title": "Log Files"
        }, 
        {
            "location": "/files/#varlogautostrapstage0log", 
            "text": "If you are using  autostrap.standalone  to\nstart the bootstrapping process, the first bootstrapping stage's output will go\nto this file. Once it launches  initialize_instance , logging will switch to\nthe second stage log file,  /var/log/initialize_instance.log  (see below).", 
            "title": "/var/log/autostrap/stage0.log"
        }, 
        {
            "location": "/files/#varlogscript_user_datalog", 
            "text": "If you are using the  AS::autostrap  Heat resource to start\nthe bootstrapping process, the first bootstrapping stage's output will go to\nthis file. Once the user-data script launches  initialize_instance , logging\nwill switch to the second stage log file  /var/log/initialize_instance.log \n(see below).", 
            "title": "/var/log/script_user_data.log"
        }, 
        {
            "location": "/files/#varloginitialize_instancelog", 
            "text": "This file contains all logging output from the  second bootstrapping\nstage . This is your most useful tool in\ninvestigating what went wrong if a machine fails to bootstrap.", 
            "title": "/var/log/initialize_instance.log"
        }, 
        {
            "location": "/topics/", 
            "text": "This section contains reference documentation on all the \ntopics\n\navailable from the \nglobal-config\n repository. Each topic's\ndocumentation contains an overview of the configuration it ships with and a\nlist of the puppet classes it declares. To enable a given configuration topic\non an instance, just add it to this instance's metadata parameter (this\nparameter is a space delimited list of topics).\n\n\nbase\n\n\nThis topic loads most of Autostrap's \npuppet-base\n\nmodule (the key handling logic of the \nssh topic\n are part of\n\npuppet-base\n but not loaded by the \nbase\n topic. \npuppet-base\n handles basic\nsystem configuration. This includes among other things:\n\n\n\n\n\n\nSetting a root password\n\n\n\n\n\n\nSetting various sysctls to sensible values\n\n\n\n\n\n\napt(8) configuration\n\n\n\n\n\n\nInstalling a few useful packages\n\n\n\n\n\n\nSane bash, vim and screen settings\n\n\n\n\n\n\nDeclared Classes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbase::role::common\n\n\nDeclares most profiles from \npuppet-base\n.  It does 'not' load \nbase::role::sshkeys\n, for instance (that is declared in the \nssh\n).\n\n\n\n\n\n\n\n\nnginx-static\n\n\nThis topic sets up a \nnginx\n web server that responds to\nyour instance's floating IP address and serves the static files it finds in\n\n/usr/share/nginx/html\n. It is meant for very simple setups, i.e. if you want\nto do anything beyond serving a bunch of static files through unencrypted HTTP\ndo not use this topic.\n\n\nDeclared Classes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnginx\n\n\nConfigures \nnginx\n.\n\n\n\n\n\n\n\n\npuppet-agent\n\n\nThis topic configures a puppet agent. It is part of our standard puppet setup\nprocess for stacks of two or more instances. If you have a puppet master that\nis not named \npuppetmaster.local\n, you will need to set the \npuppetmaster\n meta\ndata entry to its host name on all instances you deploy this topic to.\n\n\nDeclared Classes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nautopuppet::role::agent\n\n\nConfigures a puppet agent.\n\n\n\n\n\n\n\n\npuppet-master\n\n\nThis topic configures a puppet master. It is part of our standard puppet setup\nprocess for stacks consisting of two or more instances. Only configure it on the\ninstance you want to be the puppet master.\n\n\nDeclared Classes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nautopuppet::role::puppetmaster\n\n\nConfigures a puppet master.\n\n\n\n\n\n\n\n\npuppet-masterless\n\n\nThis topic configures a masterless puppet setup. This is our standard puppet\nsetup for stacks consisting of just one instance.\n\n\nDeclared Classes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nautopuppet::role::masterless\n\n\nConfigures masterless (local) puppet.\n\n\n\n\n\n\n\n\nssh\n\n\nThis topic configures an instance's \nssh\n daemon in a secure manner and\ndeploys SSH public keys from several Hiera hashes to the \nroot\n user's\n\nauthorized_keys\n file (see our \nkey deployment HOWTO\n for\ndetails on configuring authorized keys).\n\n\nDeclared Classes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nssh\n\n\nOur \npuppet module\n for ssh configuration.\n\n\n\n\n\n\n'base::role::sshkeys`\n\n\nDeploys authorized keys.", 
            "title": "Configuration Topic Reference"
        }, 
        {
            "location": "/topics/#base", 
            "text": "This topic loads most of Autostrap's  puppet-base \nmodule (the key handling logic of the  ssh topic  are part of puppet-base  but not loaded by the  base  topic.  puppet-base  handles basic\nsystem configuration. This includes among other things:    Setting a root password    Setting various sysctls to sensible values    apt(8) configuration    Installing a few useful packages    Sane bash, vim and screen settings", 
            "title": "base"
        }, 
        {
            "location": "/topics/#declared-classes", 
            "text": "base::role::common  Declares most profiles from  puppet-base .  It does 'not' load  base::role::sshkeys , for instance (that is declared in the  ssh ).", 
            "title": "Declared Classes"
        }, 
        {
            "location": "/topics/#nginx-static", 
            "text": "This topic sets up a  nginx  web server that responds to\nyour instance's floating IP address and serves the static files it finds in /usr/share/nginx/html . It is meant for very simple setups, i.e. if you want\nto do anything beyond serving a bunch of static files through unencrypted HTTP\ndo not use this topic.", 
            "title": "nginx-static"
        }, 
        {
            "location": "/topics/#declared-classes_1", 
            "text": "nginx  Configures  nginx .", 
            "title": "Declared Classes"
        }, 
        {
            "location": "/topics/#puppet-agent", 
            "text": "This topic configures a puppet agent. It is part of our standard puppet setup\nprocess for stacks of two or more instances. If you have a puppet master that\nis not named  puppetmaster.local , you will need to set the  puppetmaster  meta\ndata entry to its host name on all instances you deploy this topic to.", 
            "title": "puppet-agent"
        }, 
        {
            "location": "/topics/#declared-classes_2", 
            "text": "autopuppet::role::agent  Configures a puppet agent.", 
            "title": "Declared Classes"
        }, 
        {
            "location": "/topics/#puppet-master", 
            "text": "This topic configures a puppet master. It is part of our standard puppet setup\nprocess for stacks consisting of two or more instances. Only configure it on the\ninstance you want to be the puppet master.", 
            "title": "puppet-master"
        }, 
        {
            "location": "/topics/#declared-classes_3", 
            "text": "autopuppet::role::puppetmaster  Configures a puppet master.", 
            "title": "Declared Classes"
        }, 
        {
            "location": "/topics/#puppet-masterless", 
            "text": "This topic configures a masterless puppet setup. This is our standard puppet\nsetup for stacks consisting of just one instance.", 
            "title": "puppet-masterless"
        }, 
        {
            "location": "/topics/#declared-classes_4", 
            "text": "autopuppet::role::masterless  Configures masterless (local) puppet.", 
            "title": "Declared Classes"
        }, 
        {
            "location": "/topics/#ssh", 
            "text": "This topic configures an instance's  ssh  daemon in a secure manner and\ndeploys SSH public keys from several Hiera hashes to the  root  user's authorized_keys  file (see our  key deployment HOWTO  for\ndetails on configuring authorized keys).", 
            "title": "ssh"
        }, 
        {
            "location": "/topics/#declared-classes_5", 
            "text": "ssh  Our  puppet module  for ssh configuration.    'base::role::sshkeys`  Deploys authorized keys.", 
            "title": "Declared Classes"
        }, 
        {
            "location": "/glossary/", 
            "text": "In this section you will find explanations of terms we use to refer to various\nconcepts in the Autostrap environment.\n\n\n\n\nproject-config\n\n\nproject-config is a Git repository that contains configuration specific to a\ngiven project. It complements and overrides Autostrap's default configuration\nin the \nglobal-config\n repository. For\nreference on its structure and semantics we provide an\n\nexample project-config repository\n.\nFeel free to fork this repository and use it as a base for your own\nproject-config repository.\n\n\n\n\ntopic\n\n\nA topic is a self-contained unit of default configuration from the\n\nglobal-config\n repository. It has a\ntopic name (henceforth referred to by the placeholder 'name') and consists of\nthe following directories in \nglobal-config/puppet/hieradata\n:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclasses.d/\nname\n\n\nThis directory typically contains a file named \nclasses.yaml\n which holds the Hiera array \nclasses\n. The elements of this array are all the puppet classes required to deploy the topic in question.\n\n\n\n\n\n\nconfig.d/\nname\n\n\nThis directory contains all configuration data required by this topic. This configuration can be overriden partially or completely by the configuration in a \nproject-config\n repository.\n\n\n\n\n\n\nrepos.d/\nname\n\n\nThis directory contains \npuppet-repodeploy\n configuration specifying the repositories to be checked out when deploying the topic in question. Commonly these repositories are puppet modules required for deployment.\n\n\n\n\n\n\n\n\nTopics can be deployed using \nmasterless Puppet\n\nor by by \nadding\n it to a Puppet master's\nconfiguration. If a topic is deployed to a node in masterless fashion, all the\nYAML files in the abovementioned directories are added to this node's\nhiera.yaml. If it is added to the Puppet master's list of topics, only its\n\nconfig.d\n and \nrepos.d\n subdirectories will be added to the Puppet master's\nhiera.yaml. Class declarations for nodes/node types will have to be\n\nconfigured\n on a per-node/nodetype basis.", 
            "title": "Glossary"
        }, 
        {
            "location": "/glossary/#project-config", 
            "text": "project-config is a Git repository that contains configuration specific to a\ngiven project. It complements and overrides Autostrap's default configuration\nin the  global-config  repository. For\nreference on its structure and semantics we provide an example project-config repository .\nFeel free to fork this repository and use it as a base for your own\nproject-config repository.", 
            "title": "project-config"
        }, 
        {
            "location": "/glossary/#topic", 
            "text": "A topic is a self-contained unit of default configuration from the global-config  repository. It has a\ntopic name (henceforth referred to by the placeholder 'name') and consists of\nthe following directories in  global-config/puppet/hieradata :           classes.d/ name  This directory typically contains a file named  classes.yaml  which holds the Hiera array  classes . The elements of this array are all the puppet classes required to deploy the topic in question.    config.d/ name  This directory contains all configuration data required by this topic. This configuration can be overriden partially or completely by the configuration in a  project-config  repository.    repos.d/ name  This directory contains  puppet-repodeploy  configuration specifying the repositories to be checked out when deploying the topic in question. Commonly these repositories are puppet modules required for deployment.     Topics can be deployed using  masterless Puppet \nor by by  adding  it to a Puppet master's\nconfiguration. If a topic is deployed to a node in masterless fashion, all the\nYAML files in the abovementioned directories are added to this node's\nhiera.yaml. If it is added to the Puppet master's list of topics, only its config.d  and  repos.d  subdirectories will be added to the Puppet master's\nhiera.yaml. Class declarations for nodes/node types will have to be configured  on a per-node/nodetype basis.", 
            "title": "topic"
        }
    ]
}